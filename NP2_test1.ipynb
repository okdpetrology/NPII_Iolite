{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Made by Khalil Droubi\n",
    "###To process Iolite baseline-subtracted NP-II files for BB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "-Figure out report generation for graphs of CPS and ratios vs. time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "\n",
    "#pd.set_option(\"display.precision\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions\n",
    "def read_np2_timeseries(excel_file):\n",
    "    ''' Excel input file is your baseline corrected time series export from Iolite for the NP-II.'''\n",
    "    df = pd.read_excel(excel_file, sheet_name = None)\n",
    "    keys = df.keys()\n",
    "    header_row = 0\n",
    "    new_dict = {}\n",
    "    for key in keys:\n",
    "        if '1' in key:\n",
    "            df_test = df[key]\n",
    "\n",
    "            df_test.columns = df_test.iloc[header_row]\n",
    "            df_test = df_test.drop(header_row)\n",
    "            df_test = df_test.reset_index(drop=True)\n",
    "            \n",
    "            test1_new = df_test[['Absolute Time',\n",
    "             'Elapsed Time',\n",
    "                 'm238_CPS',\n",
    "                 'm232_CPS',\n",
    "                 'm208_CPS',\n",
    "                 'm207_CPS',\n",
    "                 'm206_CPS',\n",
    "                 'm204_CPS',\n",
    "                 'm202_CPS',]]\n",
    "            \n",
    "            new_dict[key] = test1_new\n",
    "    return new_dict\n",
    "\n",
    "def calc_CPS(np2_dict):\n",
    "    columns = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     'm238_CPS',\n",
    "     'm232_CPS',\n",
    "     'm208_CPS',\n",
    "     'm207_CPS',\n",
    "     'm206_CPS',\n",
    "     'm204_CPS',\n",
    "     'm202_CPS']\n",
    "\n",
    "    new_col = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     '238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "\n",
    "    cut_col = ['238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "\n",
    "    calc_dict = {}\n",
    "    for key in np2_dict:\n",
    "        #print(key)\n",
    "        test_df1 = np2_dict[key]\n",
    "\n",
    "        for col in columns:\n",
    "                test_df2 = test_df1.apply(lambda x: x * 62500000 if 'CPS' in x.name else x)\n",
    "        test_df2.columns = new_col\n",
    "        test_df2 = test_df2[cut_col]\n",
    "        result = pd.concat([test_df1, test_df2], axis=1)\n",
    "        \n",
    "        result['206/238'] = result.apply(lambda x: x['206_CPS']/x['238_CPS'], axis=1)\n",
    "        result['208/232'] = result.apply(lambda x: x['208_CPS']/x['232_CPS'], axis=1)\n",
    "        result['207/206'] = result.apply(lambda x: x['207_CPS']/x['206_CPS'], axis=1)\n",
    "        result['208/206'] = result.apply(lambda x: x['208_CPS']/x['206_CPS'], axis=1)\n",
    "        result['206/204'] = result.apply(lambda x: x['206_CPS']/x['204_CPS'], axis=1)\n",
    "        \n",
    "        calc_dict[key] = result\n",
    "    \n",
    "    return calc_dict\n",
    "\n",
    "def statistics_NP2(calc_dict):\n",
    "    calc_list = ['238_CPS', '232_CPS',\n",
    "           '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "           '208/232', '207/206', '208/206', '206/204']\n",
    "    mega_dict = {}\n",
    "\n",
    "    for sheet in calc_dict:\n",
    "        tester = calc_dict[sheet]\n",
    "        stats_dict = {}\n",
    "        for col in tester:\n",
    "\n",
    "            if col in calc_list:\n",
    "                #print(col)\n",
    "                df_mean = tester[col].mean()\n",
    "                stats_dict[col + '_mean'] = df_mean\n",
    "                df_precision = (2 * tester[col].sem()) / df_mean * 100\n",
    "                stats_dict[col + '_precision'] = df_precision\n",
    "        stats_dict['Time (s)'] = tester['Elapsed Time'].max()\n",
    "        \n",
    "        new_string = sheet.replace('time series data', '')\n",
    "        mega_dict[new_string] = stats_dict\n",
    "\n",
    "    df_1 = pd.DataFrame(mega_dict)\n",
    "    df_flip = pd.DataFrame.transpose(df_1)\n",
    "    return df_flip\n",
    "\n",
    "def files_process_toEXCEL(calc_dict, excel_name):\n",
    "    with pd.ExcelWriter(excel_name) as writer:\n",
    "        for sheet in calc_dict:\n",
    "            calc_dict[sheet].to_excel(writer, sheet_name = sheet, index = False)\n",
    "        \n",
    "        statistics_NP2(calc_dict).to_excel(writer, sheet_name = 'Statistics', index = True)\n",
    "\n",
    "def file_process_combine(filename):\n",
    "    calc_dict = calc_CPS(read_np2_timeseries(filename))\n",
    "    new_filename = str(filename.split('.')[0]) + '_processed.xlsx'\n",
    "    files_process_toEXCEL(calc_dict, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_process_combine('0416_ttn_SS_NP2_data1.xlsx')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
