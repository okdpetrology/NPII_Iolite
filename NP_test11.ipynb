{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Made by Khalil Droubi\n",
    "###To process Iolite baseline-subtracted NP-II files for BB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "-Do a Final Check if MSWD calculations are correct in AB_err function\n",
    "\n",
    "-Write function to chop lines up into smaller intervals, to test how long of a line we really need.\n",
    "\n",
    "-Make Age calculation work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "import math\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "\n",
    "#Graphing stuff\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "%matplotlib inline\n",
    "\n",
    "# %pip install seaborn\n",
    "# import seaborn as sns\n",
    "\n",
    "#%pip install PyPDF2\n",
    "from PyPDF2 import PdfFileMerger, PdfFileReader\n",
    "\n",
    "#%pip install pdfkit\n",
    "import pdfkit\n",
    "\n",
    "#%pip install xlsxwriter\n",
    "import xlsxwriter\n",
    "\n",
    "#pd.set_option(\"display.precision\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc207_206(work_age):\n",
    "    \n",
    "    decay_238 = 1.55125E-10\n",
    "    decay_235 = 9.8485E-10\n",
    "    decay_232 = 4.9475E-11\n",
    "    \n",
    "    working_207_206 = (1/137.818)*(math.exp(decay_238*work_age)-1) / (math.exp(decay_235*work_age) -1)\n",
    "    return working_207_206\n",
    "\n",
    "def calc206_238(work_age):\n",
    "    \n",
    "    decay_238 = 1.55125E-10\n",
    "    \n",
    "    ratio = (math.exp(decay_238 * work_age)) -1\n",
    "    \n",
    "    return ratio\n",
    "\n",
    "def age207vs206_calc(input207_206, age_guess = 1*(10**9), years_multiplier = 2):\n",
    "    work_age = age_guess\n",
    "    \n",
    "    \n",
    "    working_207_206 = calc207_206(work_age)\n",
    "\n",
    "    diff = input207_206 - working_207_206\n",
    "\n",
    "    if diff > 0:\n",
    "        #print('debug')\n",
    "        while abs(diff) > 0.00000000000000001:\n",
    "            #print('debug')\n",
    "            work_age = work_age + 1*(10**years_multiplier)\n",
    "            working_207_206 = calc207_206(work_age)\n",
    "            diff = input207_206 - working_207_206\n",
    "    if diff < 0:\n",
    "        while abs(diff) > 0.00000000000000001:\n",
    "            work_age = work_age - 1*(10**years_multiplier)\n",
    "            working_207_206 = calc207_206(work_age)\n",
    "            diff = input207_206 - working_207_206\n",
    "            \n",
    "    print('Succesful calculation!?')        \n",
    "    return work_age\n",
    "\n",
    "def age206vs238_calc(input206_238, age_guess = 1*(10**9), years_multiplier = 2):\n",
    "    work_age = age_guess\n",
    "    \n",
    "    \n",
    "    working_206_238 = calc206_238(work_age)\n",
    "\n",
    "    diff = input206_238 - working_206_238\n",
    "\n",
    "    if diff > 0:\n",
    "        #print('debug')\n",
    "        while abs(diff) > 0.00000000000000001:\n",
    "          \n",
    "            work_age = work_age + 1*(10**years_multiplier)\n",
    "            working_206_238 = calc206_238(work_age)\n",
    "            diff = input206_238 - working_206_238\n",
    "    if diff < 0:\n",
    "        while abs(diff) > 0.00000000000000001:\n",
    "            \n",
    "            work_age = work_age - 1*(10**years_multiplier)\n",
    "            working_207_206 = calc206_238(work_age)\n",
    "            diff = input206_238 - working_206_238\n",
    "            \n",
    "            \n",
    "    return work_age\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for calculation and EXCEL export\n",
    "\n",
    "def read_np2_timeseries(excel_file):\n",
    "    ''' Excel input file is your baseline corrected time series export from Iolite for the NP-II.'''\n",
    "    df = pd.read_excel(excel_file, sheet_name = None)\n",
    "    keys = df.keys()\n",
    "    header_row = 0\n",
    "    new_dict = {}\n",
    "    for key in keys:\n",
    "        if '.' in key: #Kind of hard-coded right now, so if names get weird may need to change\n",
    "            \n",
    "            df_test = df[key]\n",
    "\n",
    "            df_test.columns = df_test.iloc[header_row]\n",
    "            df_test = df_test.drop(header_row)\n",
    "            df_test = df_test.reset_index(drop=True)\n",
    "            \n",
    "#             test1_new = df_test[['Absolute Time',\n",
    "#              'Elapsed Time',\n",
    "#                  'm238_CPS',\n",
    "#                  'm232_CPS',\n",
    "#                  'm208_CPS',\n",
    "#                  'm207_CPS',\n",
    "#                  'm206_CPS',\n",
    "#                  'm204_CPS',\n",
    "#                  'm202_CPS',]]\n",
    "            \n",
    "            new_string = key.split('time')[0].rstrip()\n",
    "            new_dict[new_string] = df_test #test1_new\n",
    "    return new_dict\n",
    "\n",
    "def calc_CPS(np2_dict):\n",
    "    columns = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     'm238_CPS',\n",
    "     'm232_CPS',\n",
    "     'm208_CPS',\n",
    "     'm207_CPS',\n",
    "     'm206_CPS',\n",
    "     'm204_CPS',\n",
    "     'm202_CPS']\n",
    "\n",
    "    new_col = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     '238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "\n",
    "    cut_col = ['238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "\n",
    "    calc_dict = {}\n",
    "    for key in np2_dict:\n",
    "        #print(key)\n",
    "        test_df1 = np2_dict[key]\n",
    "\n",
    "        for col in columns:\n",
    "                test_df2 = test_df1.apply(lambda x: x * 62500000 if 'CPS' in x.name else x)\n",
    "                test_df2 = test_df2[['Absolute Time',\n",
    "             'Elapsed Time',\n",
    "                 'm238_CPS',\n",
    "                 'm232_CPS',\n",
    "                 'm208_CPS',\n",
    "                 'm207_CPS',\n",
    "                 'm206_CPS',\n",
    "                 'm204_CPS',\n",
    "                 'm202_CPS',]]\n",
    "        test_df2.columns = new_col\n",
    "        test_df2 = test_df2[cut_col]\n",
    "        result = pd.concat([test_df1, test_df2], axis=1)\n",
    "        \n",
    "         #Calculating OPZ\n",
    "        result['OPZ_238'] = result.apply(lambda x: x['m238'] - x['m238_CPS'], axis=1)\n",
    "        result['OPZ_232'] = result.apply(lambda x: x['m232'] - x['m232_CPS'], axis=1)\n",
    "        result['OPZ_208'] = result.apply(lambda x: x['m208'] - x['m208_CPS'], axis=1)\n",
    "        result['OPZ_207'] = result.apply(lambda x: x['m207'] - x['m207_CPS'], axis=1)\n",
    "        result['OPZ_206'] = result.apply(lambda x: x['m206'] - x['m206_CPS'], axis=1)\n",
    "        result['OPZ_204'] = result.apply(lambda x: x['m204'] - x['m204_CPS'], axis=1)\n",
    "        result['OPZ_202'] = result.apply(lambda x: x['m202'] - x['m202_CPS'], axis=1)\n",
    "        result['OPZ_208/206'] = result.apply(lambda x: x['OPZ_208'] / x['OPZ_206'], axis=1)\n",
    "        result['OPZ_207/206'] = result.apply(lambda x: x['OPZ_207'] / x['OPZ_206'], axis=1)\n",
    "        result['OPZ_206/204_Hg-corrected'] = result.apply(lambda x: x['OPZ_206'] / (x['OPZ_204'] - (x['OPZ_202'] * 6.87/29.86)) , axis=1)\n",
    "        \n",
    "        \n",
    "       \n",
    "        #Calculating Signal-to-Noise Ratios [V]/[V]\n",
    "        result['SNR_238'] = result.apply(lambda x: x['m238_CPS']/ x['OPZ_238'], axis=1)\n",
    "        result['SNR_232'] = result.apply(lambda x: x['m232_CPS']/ x['OPZ_232'], axis=1)\n",
    "        result['SNR_208'] = result.apply(lambda x: x['m208_CPS']/ x['OPZ_208'], axis=1)\n",
    "        result['SNR_207'] = result.apply(lambda x: x['m207_CPS']/ x['OPZ_207'], axis=1)\n",
    "        result['SNR_206'] = result.apply(lambda x: x['m206_CPS']/ x['OPZ_206'], axis=1)\n",
    "        result['SNR_204'] = result.apply(lambda x: x['m204_CPS']/ x['OPZ_204'], axis=1)\n",
    "        result['SNR_202'] = result.apply(lambda x: x['m202_CPS']/ x['OPZ_202'], axis=1)\n",
    "        \n",
    "        #Calculating Ratios\n",
    "        result['206/238'] = result.apply(lambda x: x['206_CPS']/x['238_CPS'], axis=1)\n",
    "        result['208/232'] = result.apply(lambda x: x['208_CPS']/x['232_CPS'], axis=1)\n",
    "        result['207/206'] = result.apply(lambda x: x['207_CPS']/x['206_CPS'], axis=1)\n",
    "        result['208/206'] = result.apply(lambda x: x['208_CPS']/x['206_CPS'], axis=1)\n",
    "        result['206/204'] = result.apply(lambda x: x['206_CPS']/x['204_CPS'], axis=1)\n",
    "        result['208/204'] = result.apply(lambda x: x['208_CPS']/x['204_CPS'], axis=1)\n",
    "        result['207/204'] = result.apply(lambda x: x['207_CPS']/x['204_CPS'], axis=1)\n",
    "        \n",
    "        calc_dict[key] = result\n",
    "    \n",
    "    return calc_dict\n",
    "\n",
    "def ranked_minimization(sheet, ratio, reject_percentage = 20):\n",
    "\n",
    "    mytest = tester[sheet].copy(deep=True)\n",
    "\n",
    "    df_mean_before = mytest[ratio].mean()\n",
    "    df_1std_before = mytest[ratio].std()\n",
    "    df_count_before = mytest[ratio].count()\n",
    "    df_2se_perc_before = (2 * mytest[ratio].sem()) / df_mean_before * 100\n",
    "\n",
    "    dif_mean = ratio + '_dif_from_mean'\n",
    "    dif_1SD = ratio + '_dif_from_1SD'\n",
    "    mytest[dif_mean] = mytest.apply(lambda x: abs(x[ratio] - df_mean_before), axis=1)\n",
    "    mytest[dif_1SD] = mytest.apply(lambda x: x[dif_mean] - df_1std_before, axis=1)\n",
    "\n",
    "\n",
    "    mytest2 = mytest.sort_values(by = dif_1SD, ascending = False)\n",
    "    #mytest2.head()\n",
    "\n",
    "    ratios_to_reject = int(mytest[ratio].count() * reject_percentage / 100)\n",
    "    #print(ratios_to_reject)\n",
    "\n",
    "    after_rejection = mytest2[ratios_to_reject:]\n",
    "\n",
    "    df_mean_after = after_rejection[ratio].mean()\n",
    "    df_1std_after = after_rejection[ratio].std()\n",
    "    df_count_after = after_rejection[ratio].count()\n",
    "    \n",
    "    #This is not 2SE%, should probably fix labels... KD 14 June 2021\n",
    "    df_2se_perc_after = (2 * after_rejection[ratio].std()) / df_mean_after * 100\n",
    "\n",
    "    # print(df_mean_after)\n",
    "    # print(df_1std_after)\n",
    "    # print(df_2se_perc_after)\n",
    "\n",
    "    results_dict = {}\n",
    "    \n",
    "    results_dict['avg_before'] = df_mean_before\n",
    "    results_dict['1sd_before'] = df_1std_before\n",
    "    results_dict['2se%_before'] = df_2se_perc_before\n",
    "    results_dict['avg_after'] = df_mean_after\n",
    "    results_dict['1sd_after'] = df_1std_after\n",
    "    results_dict['2σ%_after'] = df_2se_perc_after\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "def statistics_NP2(calc_dict):\n",
    "    calc_list = ['238_CPS', '232_CPS',\n",
    "           '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "           '208/232', '207/206', '208/206', '206/204','208/204','207/204'  ]\n",
    "    mega_dict = {}\n",
    "\n",
    "    for sheet in calc_dict:\n",
    "        tester = calc_dict[sheet]\n",
    "        stats_dict = {}\n",
    "        for col in tester:\n",
    "\n",
    "            if col in calc_list:\n",
    "                #print(col)\n",
    "                if '/' in col:\n",
    "                    key = col + '_before rejection'\n",
    "                else:\n",
    "                    key = col + '_mean'\n",
    "                df_mean = tester[col].mean()\n",
    "                stats_dict[key] = df_mean\n",
    "                #This is not 2SE%, should probably fix labels... KD 14 June 2021\n",
    "                df_precision = (2 * tester[col].std()) / df_mean * 100\n",
    "                stats_dict[col + '_2σ%'] = df_precision\n",
    "            if 'OPZ' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean()\n",
    "            if 'SNR' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean() \n",
    "                    \n",
    "        stats_dict['Time (s)'] = tester['Elapsed Time'].max()\n",
    "        \n",
    "        #new_string = sheet.replace('time series data', '')\n",
    "        new_string = sheet.split('time')[0].rstrip()\n",
    "        mega_dict[new_string] = stats_dict\n",
    "\n",
    "    df_1 = pd.DataFrame(mega_dict)\n",
    "    df_flip = pd.DataFrame.transpose(df_1)\n",
    "    return df_flip\n",
    "\n",
    "def statistics_ranktest(calc_dict, reject_percentage = 20):\n",
    "    calc_list = ['238_CPS', '232_CPS',\n",
    "           '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "           '208/232', '207/206', '208/206', '206/204','208/204','207/204'  ]\n",
    "    mega_dict = {}\n",
    "\n",
    "    for sheet in calc_dict:\n",
    "        tester = calc_dict[sheet]\n",
    "        stats_dict = {}\n",
    "        for col in tester:\n",
    "\n",
    "            if col in calc_list:\n",
    "                #print(col)\n",
    "                if '/' in col:\n",
    "                    key_bf = col + '_before rejection'\n",
    "                    key_af = col + '_after rejection'\n",
    "                    key_bf_se = col + '_before rejection 2se%'\n",
    "                    key_af_se = col + '_after rejection 2σ%'\n",
    "                    \n",
    "                    ranked_dict = ranked_minimization(sheet, col, reject_percentage)\n",
    "                    stats_dict[key_bf] = ranked_dict['avg_before']\n",
    "                    stats_dict[key_bf_se] = ranked_dict['2se%_before']\n",
    "                    stats_dict[key_af] = ranked_dict['avg_after']\n",
    "                    #This is not 2SE%, should probably fix labels... KD 14 June 2021\n",
    "                    stats_dict[key_af_se] = ranked_dict['2σ%_after']\n",
    "                else:\n",
    "                    key = col + '_mean'\n",
    "                    df_mean = tester[col].mean()\n",
    "                    stats_dict[key] = df_mean\n",
    "                    #This is not 2SE%, should probably fix labels... KD 14 June 2021\n",
    "                    df_precision = (2 * tester[col].std()) / df_mean * 100\n",
    "                    stats_dict[col + '_2σ%'] = df_precision\n",
    "            if 'OPZ' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean()\n",
    "            if 'SNR' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean()\n",
    "                    \n",
    "        stats_dict['Time (s)'] = tester['Elapsed Time'].max()\n",
    "        \n",
    "        #new_string = sheet.replace('time series data', '')\n",
    "        new_string = sheet.split('time')[0].rstrip()\n",
    "        mega_dict[new_string] = stats_dict\n",
    "\n",
    "    df_1 = pd.DataFrame(mega_dict)\n",
    "    df_flip = pd.DataFrame.transpose(df_1)\n",
    "    return df_flip\n",
    "\n",
    "### Getting rid of negatives\n",
    "\n",
    "def ranked_minimization2(sheet, ratio, reject_percentage = 20):\n",
    "    ''' Modified to exclude negative ratios BEFORE rejection.'''\n",
    "    \n",
    "    mytest = tester[sheet].copy(deep=True)\n",
    "\n",
    "    df_mean_before = mytest[ratio].mean()\n",
    "    df_1std_before = mytest[ratio].std()\n",
    "    df_count_before = mytest[ratio].count()\n",
    "    df_2se_perc_before = (2 * mytest[ratio].sem()) / df_mean_before * 100\n",
    "\n",
    "    dif_mean = ratio + '_dif_from_mean'\n",
    "    dif_1SD = ratio + '_dif_from_1SD'\n",
    "    mytest[dif_mean] = mytest.apply(lambda x: abs(x[ratio] - df_mean_before), axis=1)\n",
    "    mytest[dif_1SD] = mytest.apply(lambda x: x[dif_mean] - df_1std_before, axis=1)\n",
    "\n",
    "    mytest_noNeg = mytest[mytest[ratio] > 0]\n",
    "    \n",
    "    mytest2 = mytest_noNeg.sort_values(by = dif_1SD, ascending = False)\n",
    "    #mytest2.head()\n",
    "\n",
    "    ratios_to_reject = int(mytest_noNeg[ratio].count() * reject_percentage / 100)\n",
    "    #print(ratios_to_reject)\n",
    "\n",
    "    after_rejection = mytest2[ratios_to_reject:]\n",
    "    \n",
    "    \n",
    "\n",
    "    df_mean_after = after_rejection[ratio].mean()\n",
    "    df_1std_after = after_rejection[ratio].std()\n",
    "    df_count_after = after_rejection[ratio].count()\n",
    "   \n",
    "    df_2se_perc_after = (2 * after_rejection[ratio].sem()) / df_mean_after * 100\n",
    "    df_2sd_perc_after = (2 * after_rejection[ratio].std()) / df_mean_after * 100\n",
    "    \n",
    "\n",
    "    # print(df_mean_after)\n",
    "    # print(df_1std_after)\n",
    "    # print(df_2se_perc_after)\n",
    "\n",
    "    results_dict = {}\n",
    "    \n",
    "    results_dict['avg_before'] = df_mean_before\n",
    "    results_dict['1sd_before'] = df_1std_before\n",
    "    results_dict['2se%_before'] = df_2se_perc_before\n",
    "    results_dict['avg_after'] = df_mean_after\n",
    "    results_dict['1sd_after'] = df_1std_after\n",
    "    results_dict['2se%_after'] = df_2se_perc_after\n",
    "    results_dict['2σ%_after'] = df_2sd_perc_after\n",
    "    \n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "def statistics_ranktest2(calc_dict, reject_percentage = 20):\n",
    "    '''Incorporates the new ranked minimization.'''\n",
    "    calc_list = ['238_CPS', '232_CPS',\n",
    "           '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "           '208/232', '207/206', '208/206', '206/204','208/204','207/204'  ]\n",
    "    mega_dict = {}\n",
    "\n",
    "    for sheet in calc_dict:\n",
    "        tester = calc_dict[sheet]\n",
    "        stats_dict = {}\n",
    "        for col in tester:\n",
    "\n",
    "            if col in calc_list:\n",
    "                #print(col)\n",
    "                if '/' in col:\n",
    "                    key_bf = col + '_before rejection'\n",
    "                    key_af = col + '_after rejection'\n",
    "                    key_bf_se = col + '_before rejection 2se%'\n",
    "                    key_af_se = col + '_after rejection 2se%'\n",
    "                    key_af_2sd = col + '_after rejection 2σ%'\n",
    "                    \n",
    "                    ranked_dict = ranked_minimization2(sheet, col, reject_percentage)\n",
    "                    stats_dict[key_bf] = ranked_dict['avg_before']\n",
    "                    stats_dict[key_bf_se] = ranked_dict['2se%_before']\n",
    "                    stats_dict[key_af] = ranked_dict['avg_after']\n",
    "                    \n",
    "                    stats_dict[key_af_se] = ranked_dict['2se%_after']\n",
    "                    stats_dict[key_af_2sd] = ranked_dict['2σ%_after']\n",
    "                else:\n",
    "                    key = col + '_mean'\n",
    "                    df_mean = tester[col].mean()\n",
    "                    stats_dict[key] = df_mean\n",
    "                    #This is not 2SE%, should probably fix labels... KD 14 June 2021\n",
    "                    df_precision = (2 * tester[col].std()) / df_mean * 100\n",
    "                    stats_dict[col + '_2σ%'] = df_precision\n",
    "            if 'OPZ' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean()\n",
    "            if 'SNR' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean()\n",
    "                \n",
    "        stats_dict['Time (s)'] = tester['Elapsed Time'].max()\n",
    "        \n",
    "        #new_string = sheet.replace('time series data', '')\n",
    "        new_string = sheet.split('time')[0].rstrip()\n",
    "        mega_dict[new_string] = stats_dict\n",
    "\n",
    "    df_1 = pd.DataFrame(mega_dict)\n",
    "    df_flip = pd.DataFrame.transpose(df_1)\n",
    "    return df_flip\n",
    "\n",
    "def stat_grouper(stats_df):\n",
    "    ''' Input dataframe that was output from statistics_ranktest2 function.'''\n",
    "    headers_to_keep = [\n",
    "        '206/238_after rejection',\n",
    "        '206/238_after rejection 2se%',\n",
    "        '208/232_after rejection',\n",
    "        '208/232_after rejection 2se%',\n",
    "        '207/206_after rejection',\n",
    "        '207/206_after rejection 2se%',\n",
    "        '208/206_after rejection',\n",
    "        '208/206_after rejection 2se%',\n",
    "        '206/204_after rejection',\n",
    "        '206/204_after rejection 2se%',\n",
    "        '208/204_after rejection',\n",
    "        '208/204_after rejection 2se%',\n",
    "        '207/204_after rejection',\n",
    "        '207/204_after rejection 2se%'   \n",
    "    ]\n",
    "\n",
    "    headers_to_math = [\n",
    "        '206/238_after rejection',   \n",
    "        '208/232_after rejection',  \n",
    "        '207/206_after rejection',    \n",
    "        '208/206_after rejection',    \n",
    "        '206/204_after rejection',    \n",
    "        '208/204_after rejection',   \n",
    "        '207/204_after rejection',\n",
    "    ]\n",
    "\n",
    "\n",
    "    short_tester = stats_df[headers_to_keep]\n",
    "\n",
    "    samples = short_tester.index.values.tolist()\n",
    "    group = None\n",
    "    group_names = []\n",
    "    start = [0]\n",
    "    end = []\n",
    "    for idx in range(len(samples)):\n",
    "        if group == None:\n",
    "            group = samples[idx].split(' 1')[0]\n",
    "            group_names.append(group)\n",
    "        #print(samples[idx])\n",
    "        if group in samples[idx]:\n",
    "            pass\n",
    "        else:\n",
    "            end.append(idx)\n",
    "            start.append(idx + 1)\n",
    "            name = samples[idx].split(' 1')[0]\n",
    "            group = name\n",
    "            group_names.append(name)\n",
    "    end.append(len(samples))\n",
    "\n",
    "    # print('start:', start)\n",
    "    # print('end:', end)\n",
    "    # print('group names:', group_names)\n",
    "\n",
    "    stats_dict = {}\n",
    "    for idx in range(len(group_names)):\n",
    "        group_dict = {}\n",
    "        #print(idx)\n",
    "        group_df = short_tester.iloc[start[idx]:end[idx]]\n",
    "\n",
    "        for col in headers_to_math:\n",
    "            #print(group_df[col])\n",
    "            name = col.split('_')[0]\n",
    "            df_mean = group_df[col].mean()\n",
    "            #print(df_mean)\n",
    "            group_dict[name + '_mean'] = df_mean\n",
    "            df_2se_perc = (2 * group_df[col].std())/df_mean * 100\n",
    "            group_dict[name + '_2SE%'] = df_2se_perc \n",
    "\n",
    "        stats_dict[group_names[idx]] = group_dict\n",
    "\n",
    "    return pd.DataFrame(stats_dict)\n",
    "\n",
    "def stat_correcter2(stats_df, std = 'glass'):\n",
    "    ''' Input dataframe that was output from statistics_ranktest2\n",
    "    function.'''\n",
    "    headers_to_keep = [\n",
    "        '206/238_after rejection',\n",
    "        '206/238_after rejection 2se%',\n",
    "        '206/238_after rejection 2σ%',\n",
    "        '208/232_after rejection',\n",
    "        '208/232_after rejection 2se%',\n",
    "        '208/232_after rejection 2σ%',\n",
    "        '207/206_after rejection',\n",
    "        '207/206_after rejection 2se%',\n",
    "        '207/206_after rejection 2σ%',\n",
    "        '208/206_after rejection',\n",
    "        '208/206_after rejection 2se%',\n",
    "        '208/206_after rejection 2σ%',\n",
    "        '206/204_after rejection',\n",
    "        '206/204_after rejection 2se%',\n",
    "        '206/204_after rejection 2σ%',\n",
    "        '208/204_after rejection',\n",
    "        '208/204_after rejection 2se%',\n",
    "        '208/204_after rejection 2σ%',\n",
    "        '207/204_after rejection',\n",
    "        '207/204_after rejection 2se%',\n",
    "        '207/204_after rejection 2σ%',\n",
    "    ]\n",
    "\n",
    "    headers_to_math = [\n",
    "        '206/238_after rejection',   \n",
    "        '208/232_after rejection',  \n",
    "        '207/206_after rejection',    \n",
    "        '208/206_after rejection',    \n",
    "        '206/204_after rejection',    \n",
    "        '208/204_after rejection',   \n",
    "        '207/204_after rejection',\n",
    "    ]\n",
    "    \n",
    "    ### Correction Math\n",
    "    \n",
    "    #Currently hard-coded, will need to define in function at some point...\n",
    "    \n",
    "    published_ratios_610 = {\n",
    "        '206/238': 0.258174418887103,\n",
    "        '208/232': 0.546910763260703,\n",
    "        '207/206': 0.909778846717897,\n",
    "        '208/206': 2.16900334369684,\n",
    "        '206/204': 17.047,\n",
    "        '207/204': 15.509,\n",
    "        '208/204': 36.975,\n",
    "        \n",
    "    }\n",
    "    published_ratios_MKED = {\n",
    "        '206/238': 0.26538,\n",
    "        '208/232': 0.08127,\n",
    "        '207/206': 0.09465,\n",
    "        '208/206': 0.8719,\n",
    "        '206/204': 18962.2,\n",
    "        '207/204': 1794.77223,\n",
    "        '208/204': 16533.14218,      \n",
    "    }\n",
    "    published_ratios_612 = {\n",
    "        '206/238': 0.289090155580635,\n",
    "        '208/232': 0.598868250924868,\n",
    "        '207/206': 0.907335907335907,\n",
    "        '208/206': 2.16450216450216,\n",
    "        '206/204': 17.094,\n",
    "        '207/204': 15.51,\n",
    "        '208/204': 37,      \n",
    "    }\n",
    "    published_ratios_BHVO = {\n",
    "        '206/238': 1.24298582359808,\n",
    "        '208/232': 0.811596334965975,\n",
    "        '207/206': 0.831206960977953,\n",
    "        '208/206': 2.042918913147926,\n",
    "        '206/204': 18.733,\n",
    "        '207/204': 15.571,\n",
    "        '208/204': 38.27,      \n",
    "    }   \n",
    "    \n",
    "    \n",
    "    if std == 'glass':\n",
    "        #print('610 primary std')\n",
    "        published_ratios = published_ratios_610\n",
    "    elif std == '612':\n",
    "        #print('612 primary std')\n",
    "        published_ratios = published_ratios_612\n",
    "    elif std == 'BHVO':\n",
    "        #print('BHVO primary std')\n",
    "        published_ratios = published_ratios_BHVO    \n",
    "    else:\n",
    "        published_ratios = published_ratios_MKED \n",
    "    \n",
    "    short_tester = stats_df[headers_to_keep]\n",
    "    result = short_tester.copy(deep=True)\n",
    "\n",
    "    samples = short_tester.index.values.tolist()\n",
    "    group = None\n",
    "    group_names = []\n",
    "    start = [0]\n",
    "    end = []\n",
    "    for idx in range(len(samples)):\n",
    "        if group == None:\n",
    "            group = samples[idx].split(' 1')[0]\n",
    "            group_names.append(group)\n",
    "        #print(samples[idx])\n",
    "        if group in samples[idx]:\n",
    "            pass\n",
    "        else:\n",
    "            end.append(idx)\n",
    "           \n",
    "            start.append(idx)\n",
    "            name = samples[idx].split(' 1')[0]\n",
    "            group = name\n",
    "            group_names.append(name)\n",
    "    end.append(len(samples))\n",
    "\n",
    "    # print('start:', start)\n",
    "    # print('end:', end)\n",
    "    # print('group names:', group_names)\n",
    "\n",
    "    stats_dict = {}\n",
    "    corrected_stats_dict = {}\n",
    "    for idx in range(len(group_names)):\n",
    "        group_dict = {}\n",
    "        #print(idx)\n",
    "        group_df = short_tester.iloc[start[idx]:end[idx]]\n",
    "        #print(group_df.index.values.tolist())\n",
    "        for col in headers_to_math:\n",
    "            #print(group_df[col])\n",
    "            name = col.split('_')[0]\n",
    "            df_mean = group_df[col].mean()\n",
    "            #print(df_mean)\n",
    "            group_dict[name + '_mean'] = df_mean\n",
    "            #External error\n",
    "            df_2sd_perc = (2 * group_df[col].std())/df_mean * 100\n",
    "            \n",
    "            group_dict[name + '_2\\u03C3%'] = df_2sd_perc\n",
    "            \n",
    "            df_2se_perc = (2 * group_df[col].sem())/df_mean * 100\n",
    "            \n",
    "            group_dict[name + '_2se%'] = df_2se_perc\n",
    "            \n",
    "   \n",
    "\n",
    "        stats_dict[group_names[idx]] = group_dict\n",
    "    \n",
    "    grouper = pd.DataFrame(stats_dict)\n",
    "    #grouper['SRM NIST 610']['206/238_mean']\n",
    "    if std == 'glass':\n",
    "        #print('610 primary std')\n",
    "        primary_std = grouper['SRM NIST 610']\n",
    "    elif std == '612':\n",
    "        #print('612 primary std')\n",
    "        primary_std = grouper['SRM NIST 612']\n",
    "    elif std == 'BHVO':\n",
    "        #print('BHVO primary std')\n",
    "        primary_std = grouper['BHVO-2G']         \n",
    "    else:\n",
    "        primary_std = grouper['MKED']\n",
    "        \n",
    "    \n",
    "\n",
    "        #Applying correction Hard coding the primary standard\n",
    "    result['206/238 corrected'] = short_tester.apply(lambda x: x['206/238_after rejection']/ (primary_std['206/238_mean'] / published_ratios['206/238']), axis=1)\n",
    "    result['208/232 corrected'] = short_tester.apply(lambda x: x['208/232_after rejection']/ (primary_std['208/232_mean'] / published_ratios['208/232']), axis=1)\n",
    "    result['207/206 corrected'] = short_tester.apply(lambda x: x['207/206_after rejection']/ (primary_std['207/206_mean'] / published_ratios['207/206']), axis=1)\n",
    "    result['208/206 corrected'] = short_tester.apply(lambda x: x['208/206_after rejection']/(primary_std['208/206_mean'] / published_ratios['208/206']), axis=1)\n",
    "    result['206/204 corrected'] = short_tester.apply(lambda x: x['206/204_after rejection']/(primary_std['206/204_mean'] / published_ratios['206/204']), axis=1)\n",
    "    result['207/204 corrected'] = short_tester.apply(lambda x: x['207/204_after rejection']/(primary_std['207/204_mean'] / published_ratios['207/204']), axis=1)\n",
    "    result['208/204 corrected'] = short_tester.apply(lambda x: x['208/204_after rejection']/(primary_std['208/204_mean'] / published_ratios['208/204']), axis=1)\n",
    "\n",
    "#     #Making 2se for plotting in EXCEL\n",
    "    \n",
    "    result['206/238_after rejection 2se'] = short_tester.apply(lambda x: x['206/238_after rejection'] * x['206/238_after rejection 2se%'] / 100, axis=1)\n",
    "    result['208/232_after rejection 2se'] = short_tester.apply(lambda x: x['208/232_after rejection'] * x['208/232_after rejection 2se%'] / 100, axis=1)\n",
    "    result['207/206_after rejection 2se'] = short_tester.apply(lambda x: x['207/206_after rejection'] * x['207/206_after rejection 2se%'] / 100, axis=1)\n",
    "    result['208/206_after rejection 2se'] = short_tester.apply(lambda x: x['208/206_after rejection'] * x['208/206_after rejection 2se%'] / 100, axis=1)\n",
    "    result['206/204_after rejection 2se'] = short_tester.apply(lambda x: x['206/204_after rejection'] * x['206/204_after rejection 2se%'] / 100, axis=1)\n",
    "    result['207/204_after rejection 2se'] = short_tester.apply(lambda x: x['207/204_after rejection'] * x['207/204_after rejection 2se%'] / 100, axis=1)\n",
    "    result['208/204_after rejection 2se'] = short_tester.apply(lambda x: x['208/204_after rejection'] * x['208/204_after rejection 2se%'] / 100, axis=1)\n",
    "    \n",
    "    \n",
    "    #Age calculation\n",
    "    \n",
    "#     result['206/238 Age [Ma]'] = result.apply(lambda x: age206vs238_calc(x['206/238 corrected'], 500*(10**9), 6) / 1000000, axis=1)\n",
    "#     result['207/206 Age [Ma]'] = result.apply(lambda x: age207vs206_calc(x['207/206 corrected'], 500*(10**9), 6) / 1000000, axis=1)\n",
    "    \n",
    "    \n",
    "    result_headers = [\n",
    "        '206/238 corrected',\n",
    "        '208/232 corrected',\n",
    "        '207/206 corrected',\n",
    "        '208/206 corrected',\n",
    "        '206/204 corrected',\n",
    "        '207/204 corrected',\n",
    "        '208/204 corrected',\n",
    "#         '206/238 Age [Ma]',\n",
    "#         '207/206 Age [Ma]',\n",
    "    ]\n",
    "       \n",
    "    \n",
    "    for idx in range(len(group_names)):\n",
    "        group_dict = {}\n",
    "        #print(idx)\n",
    "        group_df = result.iloc[start[idx]:end[idx]]\n",
    "        #print(group_df.index.values.tolist())\n",
    "        #print(group_df)\n",
    "        for col in result_headers:\n",
    "            #print(group_df[col])\n",
    "            name = col.split('_')[0]\n",
    "            df_mean = group_df[col].mean()\n",
    "            #print(df_mean)\n",
    "            group_dict[name + '_mean'] = df_mean\n",
    "            df_2sd_perc = (2 * group_df[col].std())/df_mean * 100\n",
    "            group_dict[name + '_2\\u03C3%'] = df_2sd_perc \n",
    "            df_2sd = 2 * group_df[col].std()\n",
    "            group_dict[name + '_2\\u03C3'] = df_2sd\n",
    "            \n",
    "            df_2se_perc = (2 * group_df[col].sem())/df_mean * 100\n",
    "            group_dict[name + '_2se%'] = df_2se_perc\n",
    "            df_2se = 2 * group_df[col].sem()\n",
    "            group_dict[name + '_2se'] = df_2se\n",
    "        \n",
    "        \n",
    "\n",
    "        corrected_stats_dict[group_names[idx]] = group_dict\n",
    "  \n",
    "   \n",
    "    corrected_grouper = pd.DataFrame(corrected_stats_dict)\n",
    "   \n",
    "   \n",
    "    \n",
    "    grouper_flip = pd.DataFrame.transpose(grouper)\n",
    "    corrected_flip = pd.DataFrame.transpose(corrected_grouper)\n",
    "    grouper_list = [grouper_flip, corrected_flip]\n",
    "    \n",
    "    grouper_comb = pd.concat(grouper_list, axis=1)\n",
    "    \n",
    "    #### Propogating Errors\n",
    "    \n",
    "    if std == 'glass':\n",
    "        print('610 primary std')\n",
    "        external_err_std = grouper_comb.loc['SRM NIST 610']\n",
    "    elif std == '612':\n",
    "        print('612 primary std')\n",
    "        external_err_std = grouper_comb.loc['SRM NIST 612']\n",
    "    elif std == 'BHVO':\n",
    "        print('BHVO primary std')\n",
    "        external_err_std = grouper_comb.loc['BHVO-2G']    \n",
    "    else:\n",
    "        print('MKED primary std')\n",
    "        external_err_std = grouper_comb.loc['MKED']\n",
    "        \n",
    "    \n",
    "    \n",
    "    \n",
    "    result['206/238 corrected BB error%'] = short_tester.apply(lambda x: ((x['206/238_after rejection 2se%'])**2 + (external_err_std['206/238 corrected_2\\u03C3%'])**2)**0.5, axis=1)\n",
    "    result['208/232 corrected BB error%'] = short_tester.apply(lambda x: ((x['208/232_after rejection 2se%'])**2 + (external_err_std['208/232 corrected_2\\u03C3%'])**2)**0.5, axis=1)\n",
    "    result['207/206 corrected BB error%'] = short_tester.apply(lambda x: ((x['207/206_after rejection 2se%'])**2 + (external_err_std['207/206 corrected_2\\u03C3%'])**2)**0.5, axis=1)\n",
    "    result['208/206 corrected BB error%'] = short_tester.apply(lambda x: ((x['208/206_after rejection 2se%'])**2 + (external_err_std['208/206 corrected_2\\u03C3%'])**2)**0.5, axis=1)\n",
    "    result['206/204 corrected BB error%'] = short_tester.apply(lambda x: ((x['206/204_after rejection 2se%'])**2 + (external_err_std['206/204 corrected_2\\u03C3%'])**2)**0.5, axis=1)\n",
    "    result['207/204 corrected BB error%'] = short_tester.apply(lambda x: ((x['207/204_after rejection 2se%'])**2 + (external_err_std['207/204 corrected_2\\u03C3%'])**2)**0.5, axis=1)\n",
    "    result['208/204 corrected BB error%'] = short_tester.apply(lambda x: ((x['208/204_after rejection 2se%'])**2 + (external_err_std['208/204 corrected_2\\u03C3%'])**2)**0.5, axis=1)\n",
    " \n",
    "    result['206/238 corrected BB error'] = result.apply(lambda x: (x['206/238 corrected BB error%'])* x['206/238 corrected']/100, axis=1)\n",
    "    result['208/232 corrected BB error'] = result.apply(lambda x: (x['208/232 corrected BB error%'])* x['208/232 corrected']/100, axis=1)\n",
    "    result['207/206 corrected BB error'] = result.apply(lambda x: (x['207/206 corrected BB error%'])* x['207/206 corrected']/100, axis=1) \n",
    "    result['208/206 corrected BB error'] = result.apply(lambda x: (x['208/206 corrected BB error%'])* x['208/206 corrected']/100, axis=1)\n",
    "    result['206/204 corrected BB error'] = result.apply(lambda x: (x['206/204 corrected BB error%'])* x['206/204 corrected']/100, axis=1)   \n",
    "    result['207/204 corrected BB error'] = result.apply(lambda x: (x['207/204 corrected BB error%'])* x['207/204 corrected']/100, axis=1)\n",
    "    result['208/204 corrected BB error'] = result.apply(lambda x: (x['208/204 corrected BB error%'])* x['208/204 corrected']/100, axis=1)\n",
    "    \n",
    "   \n",
    "    \n",
    "    new_headers = [\n",
    "        '206/238 corrected BB error%',\n",
    "        '208/232 corrected BB error%',\n",
    "        '207/206 corrected BB error%',\n",
    "        '208/206 corrected BB error%',\n",
    "        '206/204 corrected BB error%',\n",
    "        '207/204 corrected BB error%',\n",
    "        '208/204 corrected BB error%',\n",
    "        '206/238 corrected BB error',\n",
    "        '208/232 corrected BB error',\n",
    "        '207/206 corrected BB error',\n",
    "        '208/206 corrected BB error',\n",
    "        '206/204 corrected BB error',\n",
    "        '207/204 corrected BB error',\n",
    "        '208/204 corrected BB error'    \n",
    "    ]\n",
    "    \n",
    "    new_stats_dict = {}\n",
    "    for idx in range(len(group_names)):\n",
    "        group_dict = {}\n",
    "        #print(idx)\n",
    "        group_df = result.iloc[start[idx]:end[idx]]\n",
    "        #print(group_df)\n",
    "        for col in new_headers:\n",
    "            #print(group_df[col])\n",
    "            #name = col.split('_')[0]\n",
    "            \n",
    "            df_mean = group_df[col].mean()\n",
    "            \n",
    "            #print(df_mean)\n",
    "            group_dict[col + '_mean'] = df_mean\n",
    "        \n",
    "        new_stats_dict[group_names[idx]] = group_dict \n",
    "            \n",
    "    extra_grouper = pd.DataFrame(new_stats_dict)\n",
    "    \n",
    "   \n",
    "    corrected_flip2 = pd.DataFrame.transpose(extra_grouper)\n",
    "    grouper_list2 = [grouper_comb, corrected_flip2]\n",
    "    \n",
    "    grouper_comb_final = pd.concat(grouper_list2, axis=1)\n",
    "    #print('GROUPER',grouper_comb_final.keys())\n",
    "    #print('RESULT', result.keys())\n",
    "    ############\n",
    "\n",
    "    \n",
    "    grouper_order = ['206/238_mean', '206/238_2σ%','206/238_2se%', '208/232_mean', '208/232_2σ%','208/232_2se%',\n",
    "       '207/206_mean', '207/206_2σ%','207/206_2se%', '208/206_mean', '208/206_2σ%', '208/206_2se%',\n",
    "       '206/204_mean', '206/204_2σ%','206/204_2se%', '208/204_mean', '208/204_2σ%','208/204_2se%',\n",
    "       '207/204_mean', '207/204_2σ%', '207/204_2se%',\n",
    "        '206/238 corrected_mean','206/238 corrected_2σ','206/238 corrected_2se%',\n",
    "       '206/238 corrected_2se',\n",
    "       '206/238 corrected_2σ%', '206/238 corrected BB error_mean', '206/238 corrected BB error%_mean',\n",
    "       '208/232 corrected_mean','208/232 corrected_2σ', '208/232 corrected_2σ%', '208/232 corrected_2se%', '208/232 corrected_2se','208/232 corrected BB error_mean', '208/232 corrected BB error%_mean',\n",
    "       '207/206 corrected_mean', '207/206 corrected_2σ', '207/206 corrected_2σ%','207/206 corrected_2se%',\n",
    "       '207/206 corrected_2se', '207/206 corrected BB error_mean','207/206 corrected BB error%_mean',\n",
    "        '208/206 corrected_mean', '208/206 corrected_2σ','208/206 corrected_2σ%', '208/206 corrected_2se%', '208/206 corrected_2se','208/206 corrected BB error_mean', '208/206 corrected BB error%_mean',\n",
    "        '206/204 corrected_mean','206/204 corrected_2σ','206/204 corrected_2σ%', '206/204 corrected_2se%',\n",
    "       '206/204 corrected_2se', '206/204 corrected BB error_mean', '206/204 corrected BB error%_mean',\n",
    "      '207/204 corrected_mean','207/204 corrected_2σ', '207/204 corrected_2σ%', '207/204 corrected_2se%', '207/204 corrected_2se', '207/204 corrected BB error_mean', '207/204 corrected BB error%_mean',\n",
    "      '208/204 corrected_mean', '208/204 corrected_2σ','208/204 corrected_2σ%','208/204 corrected_2se%',\n",
    "       '208/204 corrected_2se', '208/204 corrected BB error_mean', '208/204 corrected BB error%_mean', \n",
    "        #'206/238 Age [Ma]_mean','207/206 Age [Ma]_mean', \n",
    "        ]\n",
    "    \n",
    "    result_order = ['206/238_after rejection','206/238_after rejection 2σ%', '206/238_after rejection 2se%','206/238_after rejection 2se',\n",
    "       '208/232_after rejection','208/232_after rejection 2σ%', '208/232_after rejection 2se%','208/232_after rejection 2se',\n",
    "       '207/206_after rejection','207/206_after rejection 2σ%', '207/206_after rejection 2se%','207/206_after rejection 2se',\n",
    "       '208/206_after rejection','208/206_after rejection 2σ%', '208/206_after rejection 2se%','208/206_after rejection 2se',\n",
    "       '206/204_after rejection','206/204_after rejection 2σ%', '206/204_after rejection 2se%','206/204_after rejection 2se',\n",
    "       '208/204_after rejection','208/204_after rejection 2σ%', '208/204_after rejection 2se%','208/204_after rejection 2se',\n",
    "       '207/204_after rejection','207/204_after rejection 2σ%', '207/204_after rejection 2se%','207/204_after rejection 2se',\n",
    "       '206/238 corrected', '206/238 corrected BB error', '206/238 corrected BB error%',\n",
    "       '208/232 corrected', '208/232 corrected BB error','208/232 corrected BB error%',\n",
    "        '207/206 corrected', '207/206 corrected BB error', '207/206 corrected BB error%',\n",
    "       '208/206 corrected', '208/206 corrected BB error', '208/206 corrected BB error%',\n",
    "        '206/204 corrected', '206/204 corrected BB error', '206/204 corrected BB error%',\n",
    "        '207/204 corrected', '207/204 corrected BB error', '207/204 corrected BB error%',\n",
    "       '208/204 corrected',  '208/204 corrected BB error', '208/204 corrected BB error%',\n",
    "       # '206/238 Age [Ma]','207/206 Age [Ma]',\n",
    "                   ]\n",
    "        \n",
    "        \n",
    "    result_plotter = ['206/238 corrected', '206/238 corrected BB error', '206/238 corrected BB error%',\n",
    "       '208/232 corrected', '208/232 corrected BB error','208/232 corrected BB error%',\n",
    "        '207/206 corrected', '207/206 corrected BB error', '207/206 corrected BB error%',\n",
    "       '208/206 corrected', '208/206 corrected BB error', '208/206 corrected BB error%',\n",
    "        '206/204 corrected', '206/204 corrected BB error', '206/204 corrected BB error%',\n",
    "        '207/204 corrected', '207/204 corrected BB error', '207/204 corrected BB error%',\n",
    "       '208/204 corrected',  '208/204 corrected BB error', '208/204 corrected BB error%']\n",
    "           \n",
    "    grouper_plotter = ['206/238 corrected_mean','206/238 corrected_2σ',\n",
    "       '206/238 corrected BB error_mean',\n",
    "       '208/232 corrected_mean','208/232 corrected_2σ','208/232 corrected BB error_mean', \n",
    "       '207/206 corrected_mean', '207/206 corrected_2σ', '207/206 corrected BB error_mean',\n",
    "        '208/206 corrected_mean', '208/206 corrected_2σ','208/206 corrected BB error_mean', \n",
    "        '206/204 corrected_mean','206/204 corrected_2σ', '206/204 corrected BB error_mean', \n",
    "      '207/204 corrected_mean','207/204 corrected_2σ', '207/204 corrected BB error_mean', \n",
    "      '208/204 corrected_mean', '208/204 corrected_2σ', '208/204 corrected BB error_mean', \n",
    "        ]\n",
    "    \n",
    "    result = result[result_order]\n",
    "    grouper_comb_final = grouper_comb_final[grouper_order]\n",
    "                                                        \n",
    "    result_plot = result[result_plotter]\n",
    "    grouper_plot = grouper_comb_final[grouper_plotter]                                                    \n",
    "                                                                                                           \n",
    "    \n",
    "    return result, grouper_comb_final, result_plot, grouper_plot\n",
    "\n",
    "def AB_error2(result_df):\n",
    "    ''' Progress toward calculating the Constant Ext Error from Isoplot?'''\n",
    "    pd.set_option('mode.chained_assignment',None)\n",
    "    \n",
    "    AB_err_tester = result_df\n",
    "    result_headers = [\n",
    "        '206/238 corrected',\n",
    "        '208/232 corrected',\n",
    "        '207/206 corrected',\n",
    "        '208/206 corrected',\n",
    "        '206/204 corrected',\n",
    "        '207/204 corrected',\n",
    "        '208/204 corrected'    \n",
    "    ]\n",
    "\n",
    "    for ratio in result_headers:\n",
    "        #print(ratio)\n",
    "        error_string = str(ratio.split()[0]) + '_after rejection 2σ%'\n",
    "        new_string1 = ratio + ' 2σ'\n",
    "        #print(error_string)\n",
    "        new_string2 = ratio + ' x/(σ^2)'\n",
    "        new_string3 = ratio + ' 1/(σ^2)'\n",
    "\n",
    "        AB_err_tester[new_string1] = AB_err_tester.apply(lambda x: (x[error_string] / 100 ) * (x[ratio]), axis=1)\n",
    "\n",
    "        AB_err_tester[new_string2] = AB_err_tester.apply(lambda x: x[ratio] / ((x[new_string1] / 2)**2), axis=1)\n",
    "        AB_err_tester[new_string3] = AB_err_tester.apply(lambda x: (x[new_string2] / x[ratio]), axis=1)\n",
    "\n",
    "\n",
    "    samples = AB_err_tester.index.values.tolist()\n",
    "    group = None\n",
    "    group_names = []\n",
    "    start = [0]\n",
    "    end = []\n",
    "    for idx in range(len(samples)):\n",
    "        if group == None:\n",
    "            group = samples[idx].split(' 1')[0]\n",
    "            group_names.append(group)\n",
    "        #print(samples[idx])\n",
    "        if group in samples[idx]:\n",
    "            pass\n",
    "        else:\n",
    "            end.append(idx)\n",
    "            start.append(idx) # + 1 was original\n",
    "            name = samples[idx].split(' 1')[0]\n",
    "            group = name\n",
    "            group_names.append(name)\n",
    "    end.append(len(samples))\n",
    "\n",
    "    # print('start:', start)\n",
    "    # print('end:', end)\n",
    "    # print('group names:', group_names)\n",
    "\n",
    "    stats_dict = {}\n",
    "    corrected_stats_dict = {}\n",
    "    group_df_list = []\n",
    "    \n",
    "    for idx in range(len(group_names)):\n",
    "        group_dict = {}\n",
    "        #print(idx)\n",
    "        group_df = AB_err_tester.iloc[start[idx]:end[idx]]\n",
    "        #print(group_df.index.values.tolist())\n",
    "        for ratio in result_headers:\n",
    "            new_string2 = ratio + ' x/(σ^2)'\n",
    "            new_string3 = ratio + ' 1/(σ^2)'\n",
    "            new_string4 = ratio + ' Weighted Mean'\n",
    "            new_string5 = ratio + ' σ^2'\n",
    "            new_string6 = ratio + ' σ'\n",
    "            wtd_mean = group_df[new_string2].sum() / group_df[new_string3].sum()\n",
    "            sigma_sqrd = 1 / group_df[new_string3].sum()\n",
    "            sigma = sigma_sqrd ** 0.5\n",
    "\n",
    "            group_dict[new_string4] = wtd_mean\n",
    "            group_dict[new_string5] = sigma_sqrd\n",
    "            group_dict[new_string6] = sigma\n",
    "            \n",
    "            z_string = str(ratio.split()[0]) + '_Z'\n",
    "            group_df[z_string] = group_df.apply(lambda x: (((x[ratio] - group_dict[new_string4])**2) * x[new_string3] ), axis=1)\n",
    "            \n",
    "            new_string5b = ratio +' S-factor'\n",
    "            #new_string6 = ratio + ' count'\n",
    "            new_string7b = ratio + ' MSWD'\n",
    "            #new_string8 = ratio + ' MSWD_difference_from_1'\n",
    "\n",
    "            S_factor = group_df[z_string].sum()\n",
    "            MSWD = S_factor / (group_df[ratio].count() - 1)\n",
    "            #MSWD_dif = 1 - MSWD\n",
    "\n",
    "            group_dict[new_string5b] = S_factor\n",
    "            group_dict[new_string7b] = MSWD\n",
    "        \n",
    "        group_df_list.append(group_df)\n",
    "\n",
    "        stats_dict[group_names[idx]] = group_dict\n",
    "\n",
    "    grouper = pd.DataFrame(stats_dict) ### Will need to flip this at some point.\n",
    "    new_AB_err_tester = pd.concat(group_df_list)\n",
    "    \n",
    "    grouper_flip = pd.DataFrame.transpose(grouper)\n",
    "\n",
    "    return new_AB_err_tester, grouper_flip \n",
    "\n",
    "\n",
    "def stat_rank_and_correct(calc_dict, rank_perc = 20, std = 'glass'):\n",
    "    \n",
    "    stat_tester = statistics_ranktest2(calc_dict, rank_perc)\n",
    "    result, grouper_comb_final, result_plot, grouper_plot = stat_correcter2(stat_tester, std)\n",
    "    \n",
    "    #print('Debug')\n",
    "    stat1_order = ['238_CPS_mean', '238_CPS_2σ%', '232_CPS_mean', '232_CPS_2σ%',\n",
    "       '208_CPS_mean', '208_CPS_2σ%', '207_CPS_mean', '207_CPS_2σ%',\n",
    "       '206_CPS_mean', '206_CPS_2σ%', '204_CPS_mean', '204_CPS_2σ%',\n",
    "       '202_CPS_mean', '202_CPS_2σ%', 'OPZ_238_mean', 'OPZ_232_mean',\n",
    "       'OPZ_208_mean', 'OPZ_207_mean', 'OPZ_206_mean', 'OPZ_204_mean',\n",
    "       'OPZ_202_mean','OPZ_208/206_mean','OPZ_207/206_mean','OPZ_206/204_Hg-corrected_mean',\n",
    "        'SNR_238_mean', 'SNR_232_mean',\n",
    "       'SNR_208_mean', 'SNR_207_mean', 'SNR_206_mean', 'SNR_204_mean',\n",
    "       'SNR_202_mean', '206/238_before rejection',\n",
    "       '206/238_before rejection 2se%',  '208/232_before rejection',\n",
    "       '208/232_before rejection 2se%',  '207/206_before rejection',\n",
    "       '207/206_before rejection 2se%',  '208/206_before rejection',\n",
    "       '208/206_before rejection 2se%',  '206/204_before rejection',\n",
    "       '206/204_before rejection 2se%',  '208/204_before rejection',\n",
    "       '208/204_before rejection 2se%',  '207/204_before rejection',\n",
    "       '207/204_before rejection 2se%',  'Time (s)']\n",
    "    stat1 = stat_tester[stat1_order]\n",
    "    \n",
    "    stat2 = pd.concat([stat1, result], axis=1)\n",
    "    \n",
    "    stat_new, group2 = AB_error2(stat2)\n",
    "    \n",
    "    stat2_order = ['Time (s)','238_CPS_mean', '238_CPS_2σ%', '232_CPS_mean', '232_CPS_2σ%',\n",
    "    '208_CPS_mean', '208_CPS_2σ%', '207_CPS_mean', '207_CPS_2σ%',\n",
    "       '206_CPS_mean', '206_CPS_2σ%', '204_CPS_mean', '204_CPS_2σ%',\n",
    "       '202_CPS_mean', '202_CPS_2σ%', 'OPZ_238_mean', 'OPZ_232_mean',\n",
    "       'OPZ_208_mean', 'OPZ_207_mean', 'OPZ_206_mean', 'OPZ_204_mean',\n",
    "       'OPZ_202_mean', 'OPZ_208/206_mean','OPZ_207/206_mean','OPZ_206/204_Hg-corrected_mean',\n",
    "        'SNR_238_mean', 'SNR_232_mean',\n",
    "       'SNR_208_mean', 'SNR_207_mean', 'SNR_206_mean', 'SNR_204_mean',\n",
    "       'SNR_202_mean', '206/238_before rejection',\n",
    "       '206/238_before rejection 2se%',  '208/232_before rejection',\n",
    "       '208/232_before rejection 2se%',  '207/206_before rejection',\n",
    "       '207/206_before rejection 2se%',  '208/206_before rejection',\n",
    "       '208/206_before rejection 2se%',  '206/204_before rejection',\n",
    "       '206/204_before rejection 2se%',  '208/204_before rejection',\n",
    "       '208/204_before rejection 2se%',  '207/204_before rejection', '207/204_before rejection 2se%',  \n",
    "       '206/238_after rejection', '206/238_after rejection 2se%','206/238_after rejection 2se',\n",
    "       '208/232_after rejection', '208/232_after rejection 2se%','208/232_after rejection 2se',\n",
    "       '207/206_after rejection', '207/206_after rejection 2se%','207/206_after rejection 2se',\n",
    "       '208/206_after rejection', '208/206_after rejection 2se%','208/206_after rejection 2se',\n",
    "       '206/204_after rejection', '206/204_after rejection 2se%','206/204_after rejection 2se',\n",
    "       '208/204_after rejection', '208/204_after rejection 2se%','208/204_after rejection 2se',\n",
    "       '207/204_after rejection', '207/204_after rejection 2se%','207/204_after rejection 2se',\n",
    "       '206/238 corrected', '206/238 corrected 2σ','206/238 corrected x/(σ^2)', '206/238 corrected 1/(σ^2)', '206/238 corrected BB error', '206/238 corrected BB error%',\n",
    "       '208/232 corrected', '208/232 corrected 2σ', '208/232 corrected x/(σ^2)','208/232 corrected 1/(σ^2)', '208/232 corrected BB error','208/232 corrected BB error%',\n",
    "       '207/206 corrected', '207/206 corrected 2σ','207/206 corrected x/(σ^2)', '207/206 corrected 1/(σ^2)','207/206 corrected BB error', '207/206 corrected BB error%',\n",
    "       '208/206 corrected', '208/206 corrected 2σ', '208/206 corrected x/(σ^2)','208/206 corrected 1/(σ^2)', '208/206 corrected BB error', '208/206 corrected BB error%',\n",
    "       '206/204 corrected', '206/204 corrected 2σ', '206/204 corrected x/(σ^2)', '206/204 corrected 1/(σ^2)', '206/204 corrected BB error', '206/204 corrected BB error%',\n",
    "       '207/204 corrected','207/204 corrected 2σ', '207/204 corrected x/(σ^2)', '207/204 corrected 1/(σ^2)', '207/204 corrected BB error', '207/204 corrected BB error%',\n",
    "       '208/204 corrected', '208/204 corrected 2σ','208/204 corrected x/(σ^2)', '208/204 corrected 1/(σ^2)',  '208/204 corrected BB error', '208/204 corrected BB error%',          \n",
    "       '206/238_Z','208/232_Z', '207/206_Z', '208/206_Z', '206/204_Z', '207/204_Z','208/204_Z', \n",
    "                  # '206/238 Age [Ma]','207/206 Age [Ma]',\n",
    "        ]\n",
    "    \n",
    "    new_grouper_plot2 = group2[[\n",
    "        '206/238 corrected Weighted Mean','206/238 corrected MSWD',\n",
    "        '208/232 corrected Weighted Mean','208/232 corrected MSWD',\n",
    "        '207/206 corrected Weighted Mean','207/206 corrected MSWD',\n",
    "        '208/206 corrected Weighted Mean','208/206 corrected MSWD',\n",
    "        '206/204 corrected Weighted Mean','206/204 corrected MSWD',\n",
    "        '207/204 corrected Weighted Mean','207/204 corrected MSWD',\n",
    "        '208/204 corrected Weighted Mean','208/204 corrected MSWD',   \n",
    "    ]]\n",
    "    \n",
    "    new_grouper_plot = pd.concat([grouper_plot,new_grouper_plot2], axis = 1)\n",
    "    #print('DEBUG')\n",
    "    \n",
    "    stat2 = stat_new[stat2_order]\n",
    "    \n",
    "    group_new = pd.concat([grouper_comb_final, group2], axis = 1)\n",
    "    \n",
    "    return stat2, group_new, result_plot, new_grouper_plot\n",
    "\n",
    "\n",
    "def files_ranked_toEXCEL(calc_dict, excel_name):\n",
    "    stats = statistics_ranktest(calc_dict)\n",
    "    with pd.ExcelWriter(excel_name) as writer:\n",
    "        for sheet in calc_dict:\n",
    "            calc_dict[sheet].to_excel(writer, sheet_name = sheet, index = False)\n",
    "        \n",
    "        stats.to_excel(writer, sheet_name = 'Statistics', index = True)\n",
    "    new_filename = str(excel_name.split('.')[0]) + '_statistics.xlsx'\n",
    "    with pd.ExcelWriter(new_filename) as writer:\n",
    "        stats.to_excel(writer, sheet_name = 'Statistics', index = True)\n",
    "\n",
    "def files_process_toEXCEL(calc_dict, excel_name):\n",
    "    with pd.ExcelWriter(excel_name) as writer:\n",
    "        for sheet in calc_dict:\n",
    "            calc_dict[sheet].to_excel(writer, sheet_name = sheet, index = False)\n",
    "        \n",
    "        statistics_NP2(calc_dict).to_excel(writer, sheet_name = 'Statistics', index = True)\n",
    "\n",
    "def file_process_combine(filename):\n",
    "    calc_dict = calc_CPS(read_np2_timeseries(filename))\n",
    "    new_filename = str(filename.split('.')[0]) + '_processed.xlsx'\n",
    "    files_process_toEXCEL(calc_dict, new_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functons for graphing and report generation\n",
    "def U_Pb_plots(calc_dict, sample, choice = True):\n",
    "    key_list = ['238_CPS', '232_CPS',\n",
    "       '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "       '208/232', '207/206', '208/206', '206/204']\n",
    "    \n",
    "    zet = calc_dict[sample]\n",
    "    new_string = sample.split('time')[0].rstrip()\n",
    "    y_list = []\n",
    "    for key in key_list:\n",
    "        y_list.append(zet[key])\n",
    "    \n",
    "    x = zet['Elapsed Time']\n",
    "    \n",
    "    fig, axs = plt.subplots(4, 3, sharex = True, figsize = (12, 12))\n",
    "    fig.suptitle(new_string, fontsize=24)\n",
    "    \n",
    "    ax_list = [\n",
    "        axs[0, 0], \n",
    "        axs[0, 1],   \n",
    "        axs[0, 2], \n",
    "        axs[1, 0], \n",
    "        axs[1, 1],\n",
    "        axs[1, 2],\n",
    "        axs[2, 0], \n",
    "        axs[2, 1], \n",
    "        axs[2, 2],\n",
    "        axs[3, 0], \n",
    "        axs[3, 1], \n",
    "        axs[3, 2]   \n",
    "        ]\n",
    "\n",
    "    axs[0, 0].plot(x, y_list[0])\n",
    "    axs[0, 1].plot(x, y_list[1])\n",
    "    axs[0, 2].plot(x, y_list[2])\n",
    "    axs[1, 0].plot(x, y_list[3])\n",
    "    axs[1, 1].plot(x, y_list[4])\n",
    "    axs[1, 2].plot(x, y_list[5])\n",
    "    axs[2, 0].plot(x, y_list[6])\n",
    "    axs[2, 1].plot(x, y_list[7])\n",
    "    axs[2, 2].plot(x, y_list[8])\n",
    "    axs[3, 0].plot(x, y_list[9])\n",
    "    axs[3, 0].set(xlabel = 'Time (s)')\n",
    "    axs[3, 1].plot(x, y_list[10])\n",
    "    axs[3, 1].set(xlabel = 'Time (s)')\n",
    "    axs[3, 2].plot(x, y_list[11])\n",
    "    axs[3, 2].set(xlabel = 'Time (s)')\n",
    "    for idx in range(len(ax_list)):\n",
    "        ax_list[idx].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "        ax_list[idx].set_title(key_list[idx])\n",
    "        y_mean = [np.mean(y_list[idx])]*len(x)\n",
    "        # Plot the average line\n",
    "        mean_line = ax_list[idx].plot(x,y_mean, label='Mean', linestyle='--', color = \"black\")\n",
    "        # Make a legend\n",
    "        legend = ax_list[idx].legend(loc='upper right')\n",
    "    \n",
    "    MYDIR = (\"Figures\")\n",
    "    CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "\n",
    "    # If folder doesn't exist, then create it.\n",
    "    if not CHECK_FOLDER:\n",
    "        os.makedirs(MYDIR)\n",
    "        #print(\"created folder : \", MYDIR)\n",
    "    \n",
    "    #new_string = sample.replace('time series data', '').rstrip()\n",
    "    \n",
    "    filename = os.path.join(MYDIR, new_string + '.pdf')\n",
    "    plt.savefig(filename)\n",
    "    print('Plot for ', new_string, \" is complete.\")\n",
    "    \n",
    "    if choice == False:\n",
    "        plt.close()\n",
    "    #else:\n",
    "        #plt.close()\n",
    "        \n",
    "\n",
    "def U_Pb_report(calc_dict, intro_filename, intro = False, output_name = 'U-Pb_output.pdf'):\n",
    "    MYDIR = (\"Figures\")\n",
    "    mergedObject = PdfFileMerger()\n",
    "    \n",
    "    if intro:\n",
    "        mergedObject.append(PdfFileReader(intro_filename, 'rb'))\n",
    "        print(f'Succesfully incorporated {intro_filename} into PDF.')\n",
    "    pd.set_option('precision', 2)\n",
    "    stats = statistics_NP2(calc_dict)\n",
    "    stat_dict = {}\n",
    "    stat_dict['stat1'] = stats.iloc[:, 14:]\n",
    "    stat_dict['stat2'] = stats.iloc[:, :8]\n",
    "    stat_dict['stat3'] = stats.iloc[:, 8:14]\n",
    "    html_list = []\n",
    "\n",
    "    for key in stat_dict:\n",
    "        name = key + \".pdf\"\n",
    "        stats_html = stat_dict[key].to_html()\n",
    "        pdfkit.from_string(stats_html, name)\n",
    "        mergedObject.append(PdfFileReader(name, 'rb'))\n",
    "\n",
    "    file_list = []\n",
    "    keys = calc_dict.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        #print(key)\n",
    "        U_Pb_plots(calc_dict, key, False)\n",
    "        new_string = key.split('time')[0].rstrip()\n",
    "        filename = os.path.join(MYDIR, new_string + '.pdf')\n",
    "\n",
    "        mergedObject.append(PdfFileReader(filename, 'rb'))\n",
    "\n",
    "    if '.pdf' in output_name:\n",
    "        pass\n",
    "    else:\n",
    "        output_name = output_name + '.pdf'\n",
    "    \n",
    "    #output_name = \"U-Pb_output.pdf\"  \n",
    "    mergedObject.write(output_name)\n",
    "\n",
    "    print(f'PDF file named: {output_name} is complete.')        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Published values dictionary\n",
    "\n",
    "published_ratios_610 = {\n",
    "    '206/238': 0.258174418887103,\n",
    "    '208/232': 0.546910763260703,\n",
    "    '207/206': 0.909778846717897,\n",
    "    '208/206': 2.16900334369684,\n",
    "    '206/204': 17.047,\n",
    "    '207/204': 15.509,\n",
    "    '208/204': 36.975,\n",
    "\n",
    "}\n",
    "published_ratios_612 = {\n",
    "    '206/238': 0.289090155580635,\n",
    "    '208/232': 0.598868250924868,\n",
    "    '207/206': 0.907335907335907,\n",
    "    '208/206': 2.16450216450216,\n",
    "    '206/204': 17.094,\n",
    "    '207/204': 15.51,\n",
    "    '208/204': 37,      \n",
    "}\n",
    "published_ratios_BHVO = {\n",
    "    '206/238': 1.24298582359808,\n",
    "    '208/232': 0.811596334965975,\n",
    "    '207/206': 0.831206960977953,\n",
    "    '208/206': 2.042918913147926,\n",
    "    '206/204': 18.733,\n",
    "    '207/204': 15.571,\n",
    "    '208/204': 38.27,      \n",
    "}   \n",
    "published_ratios_BCR_2G = {\n",
    "    '206/238': 1.90697056349179,\n",
    "    '208/232': 1.09082521297421,\n",
    "    '207/206': 0.832720490274447,\n",
    "    '208/206': 2.06394884092726,\n",
    "    '206/204': 18.765,\n",
    "    '207/204': 15.626,\n",
    "    '208/204': 38.73,      \n",
    "}\n",
    "published_ratios_GSD_1G = {\n",
    "    '206/238': 0.367307298285922,\n",
    "    '208/232': 0.706245210573853,\n",
    "    '207/206': 0.80417794575821,\n",
    "    '208/206': 1.98723121712038,\n",
    "    '206/204': 19.579,\n",
    "    '207/204': 15.745,\n",
    "    '208/204': 38.908,      \n",
    "}\n",
    "published_ratios_GSE_1G = { ###These are just the GSD-1G ratios!!!!!\n",
    "    '206/238': 0.367307298285922,\n",
    "    '208/232': 0.706245210573853,\n",
    "    '207/206': 0.80417794575821,\n",
    "    '208/206': 1.98723121712038,\n",
    "    '206/204': 19.579,\n",
    "    '207/204': 15.745,\n",
    "    '208/204': 38.908,      \n",
    "}\n",
    "published_ratios_MKED = {\n",
    "    '206/238': 0.26538,\n",
    "    '208/232': 0.08127,\n",
    "    '207/206': 0.09465,\n",
    "    '208/206': 0.8719,\n",
    "    '206/204': 18962.2,\n",
    "    '207/204': 1794.77223,\n",
    "    '208/204': 16533.14218,      \n",
    "}\n",
    "published_ratios_BLR_1 = {\n",
    "    '206/238': 0.176364,\n",
    "    '208/232': 0.0533134203278787,\n",
    "    '207/206': 0.0743078,\n",
    "    '208/206': 0.17982,\n",
    "    '206/204': 975.36,\n",
    "    '207/204': 72.47686,\n",
    "    '208/204': 175.38924,      \n",
    "}\n",
    "published_ratios_OLT_1 = {\n",
    "    '206/238': 0.170681666666667,\n",
    "    '208/232': 0.0516589274888366,\n",
    "    '207/206': 0.0731801314551979,\n",
    "    '208/206': 0.58025,\n",
    "    '206/204': 1847.16667,\n",
    "    '207/204': 135.17590,\n",
    "    '208/204': 1071.81688,      \n",
    "}\n",
    "published_ratios_OLT_2 = {\n",
    "    '206/238': 0.16693,\n",
    "    '208/232': 0.05064,\n",
    "    '207/206': 0.07248,\n",
    "    '208/206': 0.63815,\n",
    "    '206/204': 1453.00000,\n",
    "    '207/204': 105.31206,\n",
    "    '208/204': 927.22713,      \n",
    "}\n",
    "published_ratios_TCB = {\n",
    "    '206/238': 0.17086,\n",
    "    '208/232': 0.05178,\n",
    "    '207/206': 0.07327,\n",
    "    '208/206': 0.63348,\n",
    "    '206/204': 2016.75000,\n",
    "    '207/204': 147.76034,\n",
    "    '208/204': 1277.56162,      \n",
    "}\n",
    "published_ratios_MudTank = {\n",
    "    '206/238': 0.052269449,\n",
    "    '208/232': 0.049381079,\n",
    "    '207/206': 0.071923689,\n",
    "    '208/206': 0.068164043,\n",
    "    '206/204': 766.0145618,\n",
    "    '207/204': 55.09459,\n",
    "    '208/204': 52.21465,      \n",
    "}\n",
    "\n",
    "published_ratios_dict = {\n",
    "    'SRM NIST 610': published_ratios_610,\n",
    "    'SRM NIST 612': published_ratios_612,\n",
    "    'BHVO-2G': published_ratios_BHVO,\n",
    "    'BCR-2G': published_ratios_BCR_2G,\n",
    "    'GSD-1G': published_ratios_GSD_1G,\n",
    "    'GSE-1G': published_ratios_GSE_1G,\n",
    "    'Bear Lake': published_ratios_BLR_1,\n",
    "    'MKED': published_ratios_MKED,\n",
    "    'Mudtank': published_ratios_MudTank,\n",
    "    'OLT-1': published_ratios_OLT_1,\n",
    "    'OLT-2': published_ratios_OLT_2,\n",
    "    'TCB': published_ratios_TCB,\n",
    "}\n",
    "\n",
    "published_df = pd.DataFrame(published_ratios_dict)\n",
    "published_df = pd.DataFrame.transpose(published_df)\n",
    "\n",
    "#Developing chronologic function\n",
    "\n",
    "#Check order in Iolite\n",
    "\n",
    "chrono_order = ['SRM NIST 610 1.1',\n",
    " 'SRM NIST 610 1.2',\n",
    " 'SRM NIST 610 1.3',\n",
    " 'SRM NIST 612 1.1',\n",
    " 'SRM NIST 612 1.2',\n",
    " 'SRM NIST 612 1.3',\n",
    " 'BHVO-2G 1.1',\n",
    " 'BHVO-2G 1.2',\n",
    " 'BHVO-2G 1.3',  \n",
    " 'BCR-2G 1.1',\n",
    " 'BCR-2G 1.2',\n",
    " 'BCR-2G 1.3',                          \n",
    " 'Bear Lake 1.1',\n",
    " 'Bear Lake 1.2',\n",
    " 'Bear Lake 1.3',\n",
    " 'MKED 1.1',\n",
    " 'MKED 1.2',\n",
    " 'MKED 1.3',              \n",
    " 'Bancroft 1.1',\n",
    " 'Bancroft 1.2',\n",
    " 'Bancroft 1.3',\n",
    " 'GSD-1G 1.1',\n",
    " 'GSD-1G 1.2',\n",
    " 'GSD-1G 1.3',              \n",
    " 'GSE-1G 1.1',\n",
    " 'GSE-1G 1.2',\n",
    " 'GSE-1G 1.3',              \n",
    " \n",
    "                \n",
    " 'SRM NIST 610 1.4',\n",
    " 'SRM NIST 610 1.5',\n",
    " 'SRM NIST 610 1.6', \n",
    " 'SRM NIST 612 1.4',\n",
    " 'SRM NIST 612 1.5',\n",
    " 'SRM NIST 612 1.6',              \n",
    " 'BHVO-2G 1.4',\n",
    " 'BHVO-2G 1.5',\n",
    " 'BHVO-2G 1.6', \n",
    " 'BCR-2G 1.4',\n",
    " 'BCR-2G 1.5',\n",
    " 'BCR-2G 1.6',                  \n",
    " 'Bear Lake 1.4',\n",
    " 'Bear Lake 1.5',\n",
    " 'Bear Lake 1.6',              \n",
    " 'MKED 1.4',\n",
    " 'MKED 1.5',\n",
    " 'MKED 1.6', \n",
    " 'Bancroft 1.4',\n",
    " 'Bancroft 1.5',\n",
    " 'Bancroft 1.6', \n",
    " 'Mudtank 1.1',\n",
    " 'Mudtank 1.2',\n",
    " 'Mudtank 1.3',  \n",
    " 'Yates 1.1',\n",
    " 'Yates 1.2',\n",
    " 'Yates 1.3', \n",
    "                \n",
    " 'Bancroft 1.7',\n",
    " 'Bancroft 1.8',\n",
    " 'Bancroft 1.9',\n",
    " 'MKED 1.7',\n",
    " 'MKED 1.8',\n",
    " 'MKED 1.9',\n",
    " 'Bear Lake 1.7',\n",
    " 'Bear Lake 1.8',\n",
    " 'Bear Lake 1.9',              \n",
    " 'BCR-2G 1.7',\n",
    " 'BCR-2G 1.8',\n",
    " 'BCR-2G 1.9',\n",
    " 'BHVO-2G 1.7',\n",
    " 'BHVO-2G 1.8',\n",
    " 'BHVO-2G 1.9',              \n",
    " 'SRM NIST 612 1.7',\n",
    " 'SRM NIST 612 1.8',\n",
    " 'SRM NIST 612 1.9',                              \n",
    " 'SRM NIST 610 1.7',\n",
    " 'SRM NIST 610 1.8',\n",
    " 'SRM NIST 610 1.9',\n",
    " \n",
    " ]\n",
    "\n",
    "\n",
    "def chronologic(result_df, order = chrono_order):\n",
    "    new_result = result_df.copy(deep=True)\n",
    "    \n",
    "    return new_result.reindex(order)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '06May_ttnSS2_NP2_baseline_corrected.xlsx'\n",
    "test_df = read_np2_timeseries(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['SRM NIST 610 1.1', 'SRM NIST 610 1.2', 'SRM NIST 610 1.3', 'SRM NIST 610 1.4', 'SRM NIST 610 1.5', 'SRM NIST 610 1.6', 'SRM NIST 610 1.7', 'SRM NIST 610 1.8', 'SRM NIST 610 1.9', 'SRM NIST 612 1.1', 'SRM NIST 612 1.2', 'SRM NIST 612 1.3', 'SRM NIST 612 1.4', 'SRM NIST 612 1.5', 'SRM NIST 612 1.6', 'SRM NIST 612 1.7', 'SRM NIST 612 1.8', 'SRM NIST 612 1.9', 'BHVO-2G 1.1', 'BHVO-2G 1.2', 'BHVO-2G 1.3', 'BHVO-2G 1.4', 'BHVO-2G 1.5', 'BHVO-2G 1.6', 'BHVO-2G 1.7', 'BHVO-2G 1.8', 'BHVO-2G 1.9', 'BCR-2G 1.1', 'BCR-2G 1.2', 'BCR-2G 1.3', 'BCR-2G 1.4', 'BCR-2G 1.5', 'BCR-2G 1.6', 'BCR-2G 1.7', 'BCR-2G 1.8', 'BCR-2G 1.9', 'GSD-1G 1.1', 'GSD-1G 1.2', 'GSD-1G 1.3', 'GSE-1G 1.1', 'GSE-1G 1.2', 'GSE-1G 1.3', 'Bear Lake 1.1', 'Bear Lake 1.2', 'Bear Lake 1.3', 'Bear Lake 1.4', 'Bear Lake 1.5', 'Bear Lake 1.6', 'Bear Lake 1.7', 'Bear Lake 1.8', 'Bear Lake 1.9', 'Bancroft 1.1', 'Bancroft 1.2', 'Bancroft 1.3', 'Bancroft 1.4', 'Bancroft 1.5', 'Bancroft 1.6', 'Bancroft 1.7', 'Bancroft 1.8', 'Bancroft 1.9', 'Yates 1.1', 'Yates 1.2', 'Yates 1.3', 'Mudtank 1.1', 'Mudtank 1.2', 'Mudtank 1.3', 'MKED 1.1', 'MKED 1.2', 'MKED 1.3', 'MKED 1.4', 'MKED 1.5', 'MKED 1.6', 'MKED 1.7', 'MKED 1.8', 'MKED 1.9'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tester = calc_CPS(test_df)\n",
    "tester.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#stat_tester.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# tester1_1, grouper_comb_final, result_plot, grouper_plot = stat_rank_and_correct(tester, std = 'glass')\n",
    "# index_list = tester1_1.keys()\n",
    "# for idx in index_list:\n",
    "#     print(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "glass612_zero_full, glass612_zero_groups, glass612_zero_full_plot, glass612_zero_groups_plot  = stat_rank_and_correct(tester, 0, '612')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "glass612_zero_groups.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "test_guy = glass612_zero_groups[['206/238_mean', '207/206_mean']]\n",
    "\n",
    "keys = test_guy.index.values.tolist()\n",
    "new_keys = ['Bear Lake', 'Bancroft', 'Yates', 'Mudtank', 'MKED']\n",
    "# for key in new_keys:\n",
    "    \n",
    "#     input2 = test_guy.loc[key]['206/238_mean']\n",
    "#     age = age206vs238_calc(input2, 1000*(10**6), 6) /1000000\n",
    "#     print(key, ' ',age)\n",
    "\n",
    "input2 = test_guy.loc['MKED']['206/238_mean']\n",
    "age206vs238_calc(input2, 1200E6, 6) /1000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "610 primary std\n",
      "610 primary std\n",
      "610 primary std\n",
      "612 primary std\n",
      "612 primary std\n",
      "612 primary std\n",
      "BHVO primary std\n",
      "BHVO primary std\n",
      "BHVO primary std\n",
      "MKED primary std\n",
      "MKED primary std\n",
      "MKED primary std\n"
     ]
    }
   ],
   "source": [
    "### Takes  2:20 to run... be careful\n",
    "glass_zero_full, glass_zero_groups, glass_zero_full_plot, glass_zero_groups_plot  = stat_rank_and_correct(tester, 0, 'glass')\n",
    "glass_20_full, glass_20_groups, glass_20_full_plot, glass_20_groups_plot = stat_rank_and_correct(tester, 20, 'glass')\n",
    "glass_40_full, glass_40_groups, glass_40_full_plot, glass_40_groups_plot = stat_rank_and_correct(tester, 40, 'glass')\n",
    "\n",
    "glass612_zero_full, glass612_zero_groups, glass612_zero_full_plot, glass612_zero_groups_plot  = stat_rank_and_correct(tester, 0, '612')\n",
    "glass612_20_full, glass612_20_groups, glass612_20_full_plot, glass612_20_groups_plot = stat_rank_and_correct(tester, 20, '612')\n",
    "glass612_40_full, glass612_40_groups, glass612_40_full_plot, glass612_40_groups_plot = stat_rank_and_correct(tester, 40, '612')\n",
    "\n",
    "glassBHVO_zero_full, glassBHVO_zero_groups, glassBHVO_zero_full_plot, glassBHVO_zero_groups_plot  = stat_rank_and_correct(tester, 0, 'BHVO')\n",
    "glassBHVO_20_full, glassBHVO_20_groups, glassBHVO_20_full_plot, glassBHVO_20_groups_plot = stat_rank_and_correct(tester, 20, 'BHVO')\n",
    "glassBHVO_40_full, glassBHVO_40_groups, glassBHVO_40_full_plot, glassBHVO_40_groups_plot = stat_rank_and_correct(tester, 40, 'BHVO')\n",
    "\n",
    "\n",
    "ttn_zero_full, ttn_zero_groups, ttn_zero_full_plot, ttn_zero_groups_plot  = stat_rank_and_correct(tester, 0, 'ttn')\n",
    "ttn_20_full, ttn_20_groups, ttn_20_full_plot, ttn_20_groups_plot = stat_rank_and_correct(tester, 20, 'ttn')\n",
    "ttn_40_full, ttn_40_groups, ttn_40_full_plot, ttn_40_groups_plot = stat_rank_and_correct(tester, 40, 'ttn')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "206/238_mean\n",
      "206/238_2σ%\n",
      "206/238_2se%\n",
      "208/232_mean\n",
      "208/232_2σ%\n",
      "208/232_2se%\n",
      "207/206_mean\n",
      "207/206_2σ%\n",
      "207/206_2se%\n",
      "208/206_mean\n",
      "208/206_2σ%\n",
      "208/206_2se%\n",
      "206/204_mean\n",
      "206/204_2σ%\n",
      "206/204_2se%\n",
      "208/204_mean\n",
      "208/204_2σ%\n",
      "208/204_2se%\n",
      "207/204_mean\n",
      "207/204_2σ%\n",
      "207/204_2se%\n",
      "206/238 corrected_mean\n",
      "206/238 corrected_2σ\n",
      "206/238 corrected_2se%\n",
      "206/238 corrected_2se\n",
      "206/238 corrected_2σ%\n",
      "206/238 corrected BB error_mean\n",
      "206/238 corrected BB error%_mean\n",
      "208/232 corrected_mean\n",
      "208/232 corrected_2σ\n",
      "208/232 corrected_2σ%\n",
      "208/232 corrected_2se%\n",
      "208/232 corrected_2se\n",
      "208/232 corrected BB error_mean\n",
      "208/232 corrected BB error%_mean\n",
      "207/206 corrected_mean\n",
      "207/206 corrected_2σ\n",
      "207/206 corrected_2σ%\n",
      "207/206 corrected_2se%\n",
      "207/206 corrected_2se\n",
      "207/206 corrected BB error_mean\n",
      "207/206 corrected BB error%_mean\n",
      "208/206 corrected_mean\n",
      "208/206 corrected_2σ\n",
      "208/206 corrected_2σ%\n",
      "208/206 corrected_2se%\n",
      "208/206 corrected_2se\n",
      "208/206 corrected BB error_mean\n",
      "208/206 corrected BB error%_mean\n",
      "206/204 corrected_mean\n",
      "206/204 corrected_2σ\n",
      "206/204 corrected_2σ%\n",
      "206/204 corrected_2se%\n",
      "206/204 corrected_2se\n",
      "206/204 corrected BB error_mean\n",
      "206/204 corrected BB error%_mean\n",
      "207/204 corrected_mean\n",
      "207/204 corrected_2σ\n",
      "207/204 corrected_2σ%\n",
      "207/204 corrected_2se%\n",
      "207/204 corrected_2se\n",
      "207/204 corrected BB error_mean\n",
      "207/204 corrected BB error%_mean\n",
      "208/204 corrected_mean\n",
      "208/204 corrected_2σ\n",
      "208/204 corrected_2σ%\n",
      "208/204 corrected_2se%\n",
      "208/204 corrected_2se\n",
      "208/204 corrected BB error_mean\n",
      "208/204 corrected BB error%_mean\n",
      "206/238 corrected Weighted Mean\n",
      "206/238 corrected σ^2\n",
      "206/238 corrected σ\n",
      "206/238 corrected S-factor\n",
      "206/238 corrected MSWD\n",
      "208/232 corrected Weighted Mean\n",
      "208/232 corrected σ^2\n",
      "208/232 corrected σ\n",
      "208/232 corrected S-factor\n",
      "208/232 corrected MSWD\n",
      "207/206 corrected Weighted Mean\n",
      "207/206 corrected σ^2\n",
      "207/206 corrected σ\n",
      "207/206 corrected S-factor\n",
      "207/206 corrected MSWD\n",
      "208/206 corrected Weighted Mean\n",
      "208/206 corrected σ^2\n",
      "208/206 corrected σ\n",
      "208/206 corrected S-factor\n",
      "208/206 corrected MSWD\n",
      "206/204 corrected Weighted Mean\n",
      "206/204 corrected σ^2\n",
      "206/204 corrected σ\n",
      "206/204 corrected S-factor\n",
      "206/204 corrected MSWD\n",
      "207/204 corrected Weighted Mean\n",
      "207/204 corrected σ^2\n",
      "207/204 corrected σ\n",
      "207/204 corrected S-factor\n",
      "207/204 corrected MSWD\n",
      "208/204 corrected Weighted Mean\n",
      "208/204 corrected σ^2\n",
      "208/204 corrected σ\n",
      "208/204 corrected S-factor\n",
      "208/204 corrected MSWD\n"
     ]
    }
   ],
   "source": [
    "keys = glassBHVO_20_groups.keys()\n",
    "for key in keys:\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_ratios = ['206/238 corrected_mean',\n",
    "       '208/232 corrected_mean', '207/206 corrected_mean',  '208/206 corrected_mean', \n",
    "        '206/204 corrected_mean', '207/204 corrected_mean','208/204 corrected_mean']\n",
    "    \n",
    "\n",
    "\n",
    "current_dict = { 'glass_zero_groups':glass_zero_groups[list_ratios],\n",
    "               \n",
    "               'glass_20_groups': glass_20_groups[list_ratios],\n",
    "                \n",
    "               'glass_40_groups':glass_40_groups[list_ratios],\n",
    "               \n",
    "              \n",
    "               'glass612_zero_groups':glass612_zero_groups[list_ratios],\n",
    "                \n",
    "               'glass612_20_groups': glass612_20_groups[list_ratios],\n",
    "               \n",
    "               'glass612_40_groups':glass612_40_groups[list_ratios],\n",
    "               \n",
    "                \n",
    "               'glassBHVO_zero_groups':glassBHVO_zero_groups[list_ratios],\n",
    "               \n",
    "               'glassBHVO_20_groups': glassBHVO_20_groups[list_ratios],\n",
    "                \n",
    "               'glassBHVO_40_groups':glassBHVO_40_groups[list_ratios]\n",
    "    \n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_name = 'Processed_LASS_data_difRejects_difStds_dif207206.xlsx'\n",
    "with pd.ExcelWriter(excel_name, engine = 'xlsxwriter') as writer:\n",
    "      # Get the xlsxwriter workbook objects.\n",
    "    workbook  = writer.book\n",
    "    col_format1 = workbook.add_format()\n",
    "    col_format2 = workbook.add_format()\n",
    "    col_format3 = workbook.add_format()\n",
    "    col_format1.set_bg_color('#E6E6FA') #Lavender\n",
    "    col_format2.set_bg_color('#98FB98') #Pale Green\n",
    "    col_format3.set_bg_color('#98FB98') #Antique White\n",
    "    \n",
    "    \n",
    "    for sheet in current_dict:\n",
    "        current_dict[sheet].to_excel(writer, sheet_name = sheet, index = True)\n",
    "        worksheet = writer.sheets[sheet]  # pull worksheet object\n",
    "        test_list = list(current_dict[sheet].keys())\n",
    "        worksheet.set_column(0, 0, 20)\n",
    "        worksheet.freeze_panes(1,1)\n",
    "        for idx in enumerate(test_list):\n",
    "            if 'full' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                elif 'corrected' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)\n",
    "                elif 'SNR_20' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format2)\n",
    "                    \n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "            elif 'groups' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                elif 'mean' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format2)\n",
    "                elif 'MSWD' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format3)\n",
    "                elif 'Weighted' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)        \n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_dict = {'glass_zero_full':glass_zero_full, \n",
    "                'glass_zero_groups':glass_zero_groups,\n",
    "               'glass_20_full': glass_20_full, \n",
    "               'glass_20_groups': glass_20_groups,\n",
    "               'glass_40_full':glass_40_full, \n",
    "               'glass_40_groups':glass_40_groups,\n",
    "               \n",
    "               'glass612_zero_full':glass612_zero_full, \n",
    "               'glass612_zero_groups':glass612_zero_groups,\n",
    "               'glass612_20_full': glass612_20_full, \n",
    "               'glass612_20_groups': glass612_20_groups,\n",
    "               'glass612_40_full':glass612_40_full, \n",
    "               'glass612_40_groups':glass612_40_groups,\n",
    "               \n",
    "               'glassBHVO_zero_full':glassBHVO_zero_full, \n",
    "               'glassBHVO_zero_groups':glassBHVO_zero_groups,\n",
    "               'glassBHVO_20_full': glassBHVO_20_full, \n",
    "               'glassBHVO_20_groups': glassBHVO_20_groups,\n",
    "               'glassBHVO_40_full':glassBHVO_40_full, \n",
    "               'glassBHVO_40_groups':glassBHVO_40_groups,\n",
    "               \n",
    "               'ttn_zero_full': ttn_zero_full, \n",
    "               'ttn_zero_groups': ttn_zero_groups,\n",
    "               'ttn_20_full': ttn_20_full, \n",
    "               'ttn_20_groups': ttn_20_groups,\n",
    "               'ttn_40_full': ttn_40_full, \n",
    "               'ttn_40_groups':ttn_40_groups\n",
    "              }\n",
    "\n",
    "plot_dict = {'glass_zero_full':glass_zero_full_plot, \n",
    "                'glass_zero_groups':glass_zero_groups_plot,\n",
    "               'glass_20_full': glass_20_full_plot, \n",
    "               'glass_20_groups': glass_20_groups_plot,\n",
    "               'glass_40_full':glass_40_full_plot, \n",
    "               'glass_40_groups':glass_40_groups_plot,\n",
    "             \n",
    "               'glass612_zero_full':glass612_zero_full_plot, \n",
    "               'glass612_zero_groups':glass612_zero_groups_plot,\n",
    "               'glass612_20_full': glass612_20_full_plot, \n",
    "               'glass612_20_groups': glass612_20_groups_plot,\n",
    "               'glass612_40_full':glass612_40_full_plot, \n",
    "               'glass612_40_groups':glass612_40_groups_plot,\n",
    "             \n",
    "               'glassBHVO_zero_full':glassBHVO_zero_full_plot, \n",
    "               'glassBHVO_zero_groups':glassBHVO_zero_groups_plot,\n",
    "               'glassBHVO_20_full': glassBHVO_20_full_plot, \n",
    "               'glassBHVO_20_groups': glassBHVO_20_groups_plot,\n",
    "               'glassBHVO_40_full':glassBHVO_40_full_plot, \n",
    "               'glassBHVO_40_groups':glassBHVO_40_groups_plot,\n",
    "             \n",
    "               'ttn_zero_full': ttn_zero_full_plot, \n",
    "               'ttn_zero_groups': ttn_zero_groups_plot,\n",
    "               'ttn_20_full': ttn_20_full_plot, \n",
    "               'ttn_20_groups': ttn_20_groups_plot,\n",
    "               'ttn_40_full': ttn_40_full_plot, \n",
    "               'ttn_40_groups':ttn_40_groups_plot\n",
    "              }\n",
    "\n",
    "chrono_dict = {\n",
    "            'glass_zero_full': chronologic(glass_zero_full), \n",
    "            'glass_zero_groups': glass_zero_groups,\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "###Export for full data worksheets\n",
    "\n",
    "\n",
    "excel_name = 'Processed_LASS_data_difRejects_difStds_newTest3.xlsx'\n",
    "with pd.ExcelWriter(excel_name, engine = 'xlsxwriter') as writer:\n",
    "      # Get the xlsxwriter workbook objects.\n",
    "    workbook  = writer.book\n",
    "    col_format1 = workbook.add_format()\n",
    "    col_format2 = workbook.add_format()\n",
    "    col_format3 = workbook.add_format()\n",
    "    col_format1.set_bg_color('#E6E6FA') #Lavender\n",
    "    col_format2.set_bg_color('#98FB98') #Pale Green\n",
    "    col_format3.set_bg_color('#98FB98') #Antique White\n",
    "    \n",
    "    \n",
    "    for sheet in export_dict:\n",
    "        export_dict[sheet].to_excel(writer, sheet_name = sheet, index = True)\n",
    "        worksheet = writer.sheets[sheet]  # pull worksheet object\n",
    "        test_list = list(export_dict[sheet].keys())\n",
    "        worksheet.set_column(0, 0, 20)\n",
    "        worksheet.freeze_panes(1,1)\n",
    "        for idx in enumerate(test_list):\n",
    "            if 'full' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                elif 'corrected' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)\n",
    "                elif 'SNR_20' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format2)\n",
    "                    \n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "            elif 'groups' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                elif 'mean' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format2)\n",
    "                elif 'MSWD' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format3)\n",
    "                elif 'Weighted' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)        \n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Export for plotting worksheets\n",
    "\n",
    "\n",
    "excel_name = 'Processed_LASS_data_difRejects_difStds_plottingNEW2.xlsx'\n",
    "\n",
    "with pd.ExcelWriter(excel_name, engine = 'xlsxwriter') as writer:\n",
    "    # Get the xlsxwriter workbook objects.\n",
    "    workbook  = writer.book\n",
    "    col_format1 = workbook.add_format()\n",
    "    col_format2 = workbook.add_format()\n",
    "    col_format3 = workbook.add_format()\n",
    "    col_format1.set_bg_color('#E6E6FA') #Lavender\n",
    "    col_format2.set_bg_color('#98FB98') #Pale Green\n",
    "    col_format3.set_bg_color('#98FB98') #Antique White\n",
    "    \n",
    "    for sheet in plot_dict:\n",
    "        \n",
    "        plot_dict[sheet].to_excel(writer, sheet_name = sheet, index = True)\n",
    "        worksheet = writer.sheets[sheet]  # pull worksheet object\n",
    "        test_list = list(plot_dict[sheet].keys())\n",
    "        worksheet.set_column(0, 0, 20)\n",
    "        worksheet.freeze_panes(1,1)\n",
    "        for idx in enumerate(test_list):\n",
    "            if 'full' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)\n",
    "            elif 'groups' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                elif 'mean' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)\n",
    "                elif 'MSWD' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format3)\n",
    "                elif 'Weighted' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format2)         \n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Export for chronologic worksheets\n",
    "\n",
    "excel_name = 'Processed_LASS_data_difRejects_difStds_Chrono_test1.xlsx'\n",
    "with pd.ExcelWriter(excel_name, engine = 'xlsxwriter') as writer:\n",
    "      # Get the xlsxwriter workbook objects.\n",
    "    workbook  = writer.book\n",
    "    col_format1 = workbook.add_format()\n",
    "    col_format2 = workbook.add_format()\n",
    "    col_format1.set_bg_color('#E6E6FA') #Lavender\n",
    "    col_format2.set_bg_color('#98FB98') #Pale Green\n",
    "    \n",
    "    for sheet in chrono_dict:\n",
    "\n",
    "        chrono_dict[sheet].to_excel(writer, sheet_name = sheet, index = True)\n",
    "        worksheet = writer.sheets[sheet]  # pull worksheet object\n",
    "        test_list = list(chrono_dict[sheet].keys())\n",
    "        worksheet.set_column(0, 0, 20)\n",
    "        worksheet.freeze_panes(1,1)\n",
    "        for idx in enumerate(test_list):\n",
    "            if 'full' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                elif 'corrected' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)\n",
    "                elif 'SNR_20' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format2)\n",
    "                elif 'OPZ' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format1)   \n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "            elif 'groups' in sheet:\n",
    "                if 'BB' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)\n",
    "                elif 'mean' in idx[1]:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20, col_format2)\n",
    "                else:\n",
    "                    worksheet.set_column(idx[0]+1, idx[0]+1, 20)    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### plotting?\n",
    "\n",
    "\n",
    "#What do I input?\n",
    "\n",
    "# plot_dict\n",
    "# group_namer\n",
    "#primary_std\n",
    "#published_df\n",
    "\n",
    "# def ratio_plot(group_namer, primary_std, plot_dict = plot_dict, published_df = published_df)\n",
    "\n",
    "\n",
    "\n",
    "# Making groups of the standards for plotting\n",
    "worksheets = list(plot_dict.keys())\n",
    "group = None\n",
    "std_names = []\n",
    "start = [0]\n",
    "end = []\n",
    "for idx in range(len(worksheets)):\n",
    "    if group == None:\n",
    "        group = worksheets[idx].split('_')[0]\n",
    "        std_names.append(group)\n",
    "    #print(samples[idx])\n",
    "    if worksheets[idx].split('_')[0] in group:\n",
    "        pass\n",
    "    else:\n",
    "        end.append(idx)\n",
    "        start.append(idx) \n",
    "        name = worksheets[idx].split('_')[0]\n",
    "        group = name\n",
    "        std_names.append(name)\n",
    "end.append(len(worksheets))\n",
    "\n",
    "#print('start:', start)\n",
    "#print('end:', end)\n",
    "#print('std names:', std_names)\n",
    "\n",
    "std_dict = {}\n",
    "\n",
    "for idx in range(len(std_names)):\n",
    "    group_dict = {}\n",
    "    std_group = worksheets[start[idx]:end[idx]]\n",
    "    #print('std_group', std_group)\n",
    "    group_dict['0%'] = std_group[0]\n",
    "    group_dict['20%'] = std_group[2]\n",
    "    group_dict['40%'] = std_group[4]\n",
    "    \n",
    "    group_dict['0% group'] = std_group[1]\n",
    "    group_dict['20% group'] = std_group[3]\n",
    "    group_dict['40% group'] = std_group[5]\n",
    "    \n",
    "    std_dict[std_names[idx]] = group_dict\n",
    "\n",
    "\n",
    "#Creating loop for all entries in plot_dict\n",
    "\n",
    "plot_dict_grouped_dict = {}\n",
    "\n",
    "for key in plot_dict:\n",
    "    \n",
    "    if 'full' in key:\n",
    "        \n",
    "    #Create groups for plotting\n",
    "\n",
    "        samples = plot_dict[key].index.values.tolist()\n",
    "        group = None\n",
    "        group_names = []\n",
    "        start = [0]\n",
    "        end = []\n",
    "        for idx in range(len(samples)):\n",
    "            if group == None:\n",
    "                group = samples[idx].split(' 1')[0]\n",
    "                group_names.append(group)\n",
    "            #print(samples[idx])\n",
    "            if group in samples[idx]:\n",
    "                pass\n",
    "            else:\n",
    "                end.append(idx)\n",
    "                start.append(idx) # + 1 was original\n",
    "                name = samples[idx].split(' 1')[0]\n",
    "                group = name\n",
    "                group_names.append(name)\n",
    "        end.append(len(samples))\n",
    "\n",
    "        #print('start:', start)\n",
    "        #print('end:', end)\n",
    "        #print('group names:', group_names)\n",
    "\n",
    "        group_df_list = []\n",
    "        group_df_dict = {}\n",
    "\n",
    "        for idx in range(len(group_names)):\n",
    "            group_dict = {}\n",
    "            #print(idx)\n",
    "            group_df = plot_dict[key].iloc[start[idx]:end[idx]]\n",
    "            #print(group_df.index.values.tolist())\n",
    "\n",
    "            group_df_list.append(group_df)\n",
    "            group_df_dict[group_names[idx]] = group_df\n",
    "        \n",
    "        plot_dict_grouped_dict[key] = group_df_dict\n",
    "        \n",
    "        if 'group' in key:\n",
    "             plot_dict_grouped_dict[key] = plot_dict[key]\n",
    "\n",
    "\n",
    "#Data to be plotted\n",
    "\n",
    "\n",
    "group_namer = 'SRM NIST 612'\n",
    "primary_std = 'glass612'\n",
    "\n",
    "primary_std_name = {\n",
    "    'glass': \"SRM NIST 610\",\n",
    "    'glass612': \"SRM NIST 612\",\n",
    "    'glassBHVO': \"BHVO-2G\",\n",
    "    'ttn': \"MKED-1\",\n",
    "}\n",
    "\n",
    "test_zero = plot_dict_grouped_dict[ std_dict[primary_std]['0%']][group_namer]\n",
    "test_20 = plot_dict_grouped_dict[ std_dict[primary_std]['20%']][group_namer]\n",
    "test_40 = plot_dict_grouped_dict[ std_dict[primary_std]['40%']][group_namer]\n",
    "\n",
    "test_group_zero = plot_dict[std_dict[primary_std]['0% group']].loc[group_namer]\n",
    "test_group_20 = plot_dict[std_dict[primary_std]['20% group']].loc[group_namer]\n",
    "test_group_40 = plot_dict[std_dict[primary_std]['40% group']].loc[group_namer]\n",
    "\n",
    "\n",
    "if (group_namer == 'Bancroft') or (group_namer =='Yates'):\n",
    "    #print('debug')\n",
    "    pub_ratio = published_df.loc[['OLT-1', 'OLT-2', 'TCB']]\n",
    "else:\n",
    "    pub_ratio = published_df.loc[group_namer]\n",
    "\n",
    "\n",
    "color_dict = {\n",
    "    '0%': 'red',\n",
    "    '20%': 'blue',\n",
    "    '40%': 'green',\n",
    "    'pub': 'purple'\n",
    "}\n",
    "\n",
    "\n",
    "#Initialize plots\n",
    "fig, axs = plt.subplots(2, 2, sharex = False, figsize = (24, 12))\n",
    "fig.suptitle(group_namer + ', Primary Std: ' + primary_std_name[primary_std], fontsize=28)\n",
    "\n",
    "#207/204 vs 206/204 plot\n",
    "    #Results for each line\n",
    "x1_entry = '206/204 corrected'\n",
    "y1_entry = '207/204 corrected'\n",
    "ax = axs[0,0]\n",
    "plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "ax.plot(test_zero[x1_entry], test_zero[y1_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "ax.plot(test_20[x1_entry], test_20[y1_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "ax.plot(test_40[x1_entry], test_40[y1_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "    #Group averages\n",
    "x1_entry = '206/204 corrected_mean'\n",
    "y1_entry = '207/204 corrected_mean'\n",
    "ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    #Group 2sigma\n",
    "x_error = '206/204 corrected_2σ'\n",
    "y_error = '206/204 corrected_2σ'\n",
    "ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "    #Published value\n",
    "x1_entry = '206/204'\n",
    "y1_entry = '207/204'\n",
    "ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "    #Formatting\n",
    "ax.set(xlabel = '206/204', ylabel = '207/204',)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "\n",
    "\n",
    "#208/204 vs 206/204 plot\n",
    "\n",
    "x2_entry = '206/204 corrected'\n",
    "y2_entry = '208/204 corrected'\n",
    "ax = axs[0,1]\n",
    "plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "ax.plot(test_zero[x2_entry], test_zero[y2_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "ax.plot(test_20[x2_entry], test_20[y2_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "ax.plot(test_40[x2_entry], test_40[y2_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "\n",
    "x1_entry = '206/204 corrected_mean'\n",
    "y1_entry = '208/204 corrected_mean'\n",
    "ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    " #Group 2sigma\n",
    "x_error = '206/204 corrected_2σ'\n",
    "y_error = '208/204 corrected_2σ'\n",
    "ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "\n",
    " #Published value\n",
    "x1_entry = '206/204'\n",
    "y1_entry = '208/204'\n",
    "ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "#Formatting\n",
    "ax.set(xlabel = '206/204', ylabel = '208/204',)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "\n",
    "\n",
    "\n",
    "#207/206 vs 208/206 plot\n",
    "\n",
    "x3_entry = '208/206 corrected'\n",
    "y3_entry = '207/206 corrected'\n",
    "ax = axs[1,0]\n",
    "plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "\n",
    "custom_lines = ax.plot(test_zero[x3_entry], test_zero[y3_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "ax.plot(test_20[x3_entry], test_20[y3_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "ax.plot(test_40[x3_entry], test_40[y3_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "\n",
    "x1_entry = '208/206 corrected_mean'\n",
    "y1_entry = '207/206 corrected_mean'\n",
    "ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    " #Group 2sigma\n",
    "x_error = '208/206 corrected_2σ'\n",
    "y_error = '207/206 corrected_2σ'\n",
    "ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "\n",
    " #Published value\n",
    "x1_entry = '208/206'\n",
    "y1_entry = '207/206'\n",
    "ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "#Formatting\n",
    "ax.set(xlabel = '208/206', ylabel = '207/206',)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "\n",
    "\n",
    "#206/238 vs 208/232 plot\n",
    "\n",
    "x4_entry = '208/232 corrected'\n",
    "y4_entry = '206/238 corrected'\n",
    "ax = axs[1,1]\n",
    "plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "ax.plot(test_zero[x4_entry], test_zero[y4_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "ax.plot(test_20[x4_entry], test_20[y4_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "ax.plot(test_40[x4_entry], test_40[y4_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "\n",
    "x1_entry = '208/232 corrected_mean'\n",
    "y1_entry = '206/238 corrected_mean'\n",
    "ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    " #Group 2sigma\n",
    "x_error = '208/232 corrected_2σ'\n",
    "y_error = '206/238 corrected_2σ'\n",
    "ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "\n",
    " #Published value\n",
    "x1_entry = '208/232'\n",
    "y1_entry = '206/238'\n",
    "ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "#Formatting\n",
    "ax.set(xlabel = '208/232', ylabel = '206/238',)\n",
    "ax.yaxis.label.set_size(20)\n",
    "ax.xaxis.label.set_size(20)\n",
    "\n",
    "# Make a legend\n",
    "\n",
    "patch_0 = mpatches.Patch(color= color_dict['0%'], label= '0% Rejection')\n",
    "patch_20 = mpatches.Patch(color=color_dict['20%'], label= '20% Rejection')\n",
    "patch_40 = mpatches.Patch(color=color_dict['40%'], label= '40% Rejection')\n",
    "patch_pub = mpatches.Patch(color=color_dict['pub'], label= 'Published Data')\n",
    "plt.legend(handles=[patch_0, patch_20, patch_40, patch_pub])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dict_grouped_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_plot(group_namer, primary_std, choice = True, plot_dict = plot_dict, published_df = published_df):\n",
    "\n",
    "    # Making groups of the standards for plotting\n",
    "    worksheets = list(plot_dict.keys())\n",
    "    group = None\n",
    "    std_names = []\n",
    "    start = [0]\n",
    "    end = []\n",
    "    for idx in range(len(worksheets)):\n",
    "        if group == None:\n",
    "            group = worksheets[idx].split('_')[0]\n",
    "            std_names.append(group)\n",
    "        #print(samples[idx])\n",
    "        if worksheets[idx].split('_')[0] in group:\n",
    "            pass\n",
    "        else:\n",
    "            end.append(idx)\n",
    "            start.append(idx) \n",
    "            name = worksheets[idx].split('_')[0]\n",
    "            group = name\n",
    "            std_names.append(name)\n",
    "    end.append(len(worksheets))\n",
    "\n",
    "    #print('start:', start)\n",
    "    #print('end:', end)\n",
    "    #print('std names:', std_names)\n",
    "\n",
    "    std_dict = {}\n",
    "\n",
    "    for idx in range(len(std_names)):\n",
    "        group_dict = {}\n",
    "        std_group = worksheets[start[idx]:end[idx]]\n",
    "        #print('std_group', std_group)\n",
    "        group_dict['0%'] = std_group[0]\n",
    "        group_dict['20%'] = std_group[2]\n",
    "        group_dict['40%'] = std_group[4]\n",
    "\n",
    "        group_dict['0% group'] = std_group[1]\n",
    "        group_dict['20% group'] = std_group[3]\n",
    "        group_dict['40% group'] = std_group[5]\n",
    "\n",
    "        std_dict[std_names[idx]] = group_dict\n",
    "\n",
    "\n",
    "    #Creating loop for all entries in plot_dict\n",
    "\n",
    "    plot_dict_grouped_dict = {}\n",
    "\n",
    "    for key in plot_dict:\n",
    "\n",
    "        if 'full' in key:\n",
    "\n",
    "        #Create groups for plotting\n",
    "\n",
    "            samples = plot_dict[key].index.values.tolist()\n",
    "            group = None\n",
    "            group_names = []\n",
    "            start = [0]\n",
    "            end = []\n",
    "            for idx in range(len(samples)):\n",
    "                if group == None:\n",
    "                    group = samples[idx].split(' 1')[0]\n",
    "                    group_names.append(group)\n",
    "                #print(samples[idx])\n",
    "                if group in samples[idx]:\n",
    "                    pass\n",
    "                else:\n",
    "                    end.append(idx)\n",
    "                    start.append(idx) # + 1 was original\n",
    "                    name = samples[idx].split(' 1')[0]\n",
    "                    group = name\n",
    "                    group_names.append(name)\n",
    "            end.append(len(samples))\n",
    "\n",
    "            #print('start:', start)\n",
    "            #print('end:', end)\n",
    "            #print('group names:', group_names)\n",
    "\n",
    "            group_df_list = []\n",
    "            group_df_dict = {}\n",
    "\n",
    "            for idx in range(len(group_names)):\n",
    "                group_dict = {}\n",
    "                #print(idx)\n",
    "                group_df = plot_dict[key].iloc[start[idx]:end[idx]]\n",
    "                #print(group_df.index.values.tolist())\n",
    "\n",
    "                group_df_list.append(group_df)\n",
    "                group_df_dict[group_names[idx]] = group_df\n",
    "\n",
    "            plot_dict_grouped_dict[key] = group_df_dict\n",
    "\n",
    "            if 'group' in key:\n",
    "                 plot_dict_grouped_dict[key] = plot_dict[key]\n",
    "\n",
    "\n",
    "    #Data to be plotted\n",
    "\n",
    "\n",
    "#     group_namer = 'Mudtank'\n",
    "#     primary_std = 'ttn'\n",
    "\n",
    "    primary_std_name = {\n",
    "        'glass': \"SRM NIST 610\",\n",
    "        'glass612': \"SRM NIST 612\",\n",
    "        'glassBHVO': \"BHVO-2G\",\n",
    "        'ttn': \"MKED-1\",\n",
    "    }\n",
    "\n",
    "    test_zero = plot_dict_grouped_dict[ std_dict[primary_std]['0%']][group_namer]\n",
    "    test_20 = plot_dict_grouped_dict[ std_dict[primary_std]['20%']][group_namer]\n",
    "    test_40 = plot_dict_grouped_dict[ std_dict[primary_std]['40%']][group_namer]\n",
    "\n",
    "    test_group_zero = plot_dict[std_dict[primary_std]['0% group']].loc[group_namer]\n",
    "    test_group_20 = plot_dict[std_dict[primary_std]['20% group']].loc[group_namer]\n",
    "    test_group_40 = plot_dict[std_dict[primary_std]['40% group']].loc[group_namer]\n",
    "\n",
    "\n",
    "    if (group_namer == 'Bancroft') or (group_namer =='Yates'):\n",
    "        #print('debug')\n",
    "        pub_ratio = published_df.loc[['OLT-1', 'OLT-2', 'TCB']]\n",
    "    else:\n",
    "        pub_ratio = published_df.loc[group_namer]\n",
    "\n",
    "\n",
    "    color_dict = {\n",
    "        '0%': 'red',\n",
    "        '20%': 'blue',\n",
    "        '40%': 'green',\n",
    "        'pub': 'purple'\n",
    "    }\n",
    "\n",
    "\n",
    "    #Initialize plots\n",
    "    fig, axs = plt.subplots(2, 2, sharex = False, figsize = (24, 12))\n",
    "    fig.suptitle(group_namer + ', Primary Std: ' + primary_std_name[primary_std], fontsize=28)\n",
    "\n",
    "    #207/204 vs 206/204 plot\n",
    "        #Results for each line\n",
    "    x1_entry = '206/204 corrected'\n",
    "    y1_entry = '207/204 corrected'\n",
    "    ax = axs[0,0]\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "    ax.plot(test_zero[x1_entry], test_zero[y1_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "    ax.plot(test_20[x1_entry], test_20[y1_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "    ax.plot(test_40[x1_entry], test_40[y1_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "        #Group averages\n",
    "    x1_entry = '206/204 corrected_mean'\n",
    "    y1_entry = '207/204 corrected_mean'\n",
    "    ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "        #Group 2sigma\n",
    "    x_error = '206/204 corrected_2σ'\n",
    "    y_error = '206/204 corrected_2σ'\n",
    "    ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "        #Published value\n",
    "    x1_entry = '206/204'\n",
    "    y1_entry = '207/204'\n",
    "    ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "        #Formatting\n",
    "    ax.set(xlabel = '206/204', ylabel = '207/204',)\n",
    "    ax.yaxis.label.set_size(20)\n",
    "    ax.xaxis.label.set_size(20)\n",
    "\n",
    "\n",
    "    #208/204 vs 206/204 plot\n",
    "\n",
    "    x2_entry = '206/204 corrected'\n",
    "    y2_entry = '208/204 corrected'\n",
    "    ax = axs[0,1]\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "    ax.plot(test_zero[x2_entry], test_zero[y2_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "    ax.plot(test_20[x2_entry], test_20[y2_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "    ax.plot(test_40[x2_entry], test_40[y2_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "\n",
    "    x1_entry = '206/204 corrected_mean'\n",
    "    y1_entry = '208/204 corrected_mean'\n",
    "    ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "     #Group 2sigma\n",
    "    x_error = '206/204 corrected_2σ'\n",
    "    y_error = '208/204 corrected_2σ'\n",
    "    ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "\n",
    "     #Published value\n",
    "    x1_entry = '206/204'\n",
    "    y1_entry = '208/204'\n",
    "    ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "    #Formatting\n",
    "    ax.set(xlabel = '206/204', ylabel = '208/204',)\n",
    "    ax.yaxis.label.set_size(20)\n",
    "    ax.xaxis.label.set_size(20)\n",
    "\n",
    "\n",
    "\n",
    "    #207/206 vs 208/206 plot\n",
    "\n",
    "    x3_entry = '208/206 corrected'\n",
    "    y3_entry = '207/206 corrected'\n",
    "    ax = axs[1,0]\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "\n",
    "    custom_lines = ax.plot(test_zero[x3_entry], test_zero[y3_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "    ax.plot(test_20[x3_entry], test_20[y3_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "    ax.plot(test_40[x3_entry], test_40[y3_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "\n",
    "    x1_entry = '208/206 corrected_mean'\n",
    "    y1_entry = '207/206 corrected_mean'\n",
    "    ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "     #Group 2sigma\n",
    "    x_error = '208/206 corrected_2σ'\n",
    "    y_error = '207/206 corrected_2σ'\n",
    "    ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "\n",
    "     #Published value\n",
    "    x1_entry = '208/206'\n",
    "    y1_entry = '207/206'\n",
    "    ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "    #Formatting\n",
    "    ax.set(xlabel = '208/206', ylabel = '207/206',)\n",
    "    ax.yaxis.label.set_size(20)\n",
    "    ax.xaxis.label.set_size(20)\n",
    "\n",
    "\n",
    "    #206/238 vs 208/232 plot\n",
    "\n",
    "    x4_entry = '208/232 corrected'\n",
    "    y4_entry = '206/238 corrected'\n",
    "    ax = axs[1,1]\n",
    "    plt.setp(ax.get_xticklabels(), fontsize=16)\n",
    "    plt.setp(ax.get_yticklabels(), fontsize=16)\n",
    "\n",
    "    ax.plot(test_zero[x4_entry], test_zero[y4_entry], 'o', color= color_dict['0%']) #0% reject\n",
    "    ax.plot(test_20[x4_entry], test_20[y4_entry], 'o', color= color_dict['20%']) #20% reject\n",
    "    ax.plot(test_40[x4_entry], test_40[y4_entry], 'o', color= color_dict['40%']) #40% reject\n",
    "\n",
    "    x1_entry = '208/232 corrected_mean'\n",
    "    y1_entry = '206/238 corrected_mean'\n",
    "    ax.plot(test_group_zero[x1_entry], test_group_zero[y1_entry], '^', color= color_dict['0%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_20[x1_entry], test_group_20[y1_entry], '^', color= color_dict['20%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "    ax.plot(test_group_40[x1_entry], test_group_40[y1_entry], '^', color= color_dict['40%'], markersize=14, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "     #Group 2sigma\n",
    "    x_error = '208/232 corrected_2σ'\n",
    "    y_error = '206/238 corrected_2σ'\n",
    "    ax.errorbar(test_group_zero[x1_entry], test_group_zero[y1_entry],test_group_zero[x_error], test_group_zero[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_20[x1_entry], test_group_20[y1_entry],test_group_20[x_error], test_group_20[y_error],color = 'black')\n",
    "    ax.errorbar(test_group_40[x1_entry], test_group_40[y1_entry],test_group_40[x_error], test_group_40[y_error],color = 'black')\n",
    "\n",
    "     #Published value\n",
    "    x1_entry = '208/232'\n",
    "    y1_entry = '206/238'\n",
    "    ax.plot(pub_ratio[x1_entry], pub_ratio[y1_entry], 's', color= color_dict['pub'], markersize=18, markeredgewidth=1.5, markeredgecolor= 'black') #0% reject\n",
    "\n",
    "    #Formatting\n",
    "    ax.set(xlabel = '208/232', ylabel = '206/238',)\n",
    "    ax.yaxis.label.set_size(20)\n",
    "    ax.xaxis.label.set_size(20)\n",
    "\n",
    "    # Make a legend\n",
    "\n",
    "    patch_0 = mpatches.Patch(color= color_dict['0%'], label= '0% Rejection')\n",
    "    patch_20 = mpatches.Patch(color=color_dict['20%'], label= '20% Rejection')\n",
    "    patch_40 = mpatches.Patch(color=color_dict['40%'], label= '40% Rejection')\n",
    "    patch_pub = mpatches.Patch(color=color_dict['pub'], label= 'Published Data')\n",
    "    plt.legend(handles=[patch_0, patch_20, patch_40, patch_pub])\n",
    "\n",
    "\n",
    "    MYDIR = (\"Ratio_Figures\")\n",
    "    CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "\n",
    "    # If folder doesn't exist, then create it.\n",
    "    if not CHECK_FOLDER:\n",
    "        os.makedirs(MYDIR)\n",
    "        #print(\"created folder : \", MYDIR)\n",
    "    \n",
    "    new_string = group_namer + '_PrimaryStd_' + primary_std_name[primary_std]\n",
    "    \n",
    "    filename = os.path.join(MYDIR, new_string + '.pdf')\n",
    "    plt.savefig(filename)\n",
    "    print('Plot for ', new_string, \" is complete.\")\n",
    "    \n",
    "    if choice == False:\n",
    "        plt.close()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ratio_report(plot_dict = plot_dict, intro_filename = 'fake.pdf', intro = False, output_name = 'ratio_output.pdf'):\n",
    "    \n",
    "    MYDIR = (\"Ratio_Figures\")\n",
    "    mergedObject = PdfFileMerger()\n",
    "    \n",
    "    if intro:\n",
    "        mergedObject.append(PdfFileReader(intro_filename, 'rb'))\n",
    "        print(f'Succesfully incorporated {intro_filename} into PDF.')\n",
    "    \n",
    "    \n",
    "    #Actual loop of plotting\n",
    "    \n",
    "    # Making groups of the standards for plotting\n",
    "    worksheets = list(plot_dict.keys())\n",
    "    group = None\n",
    "    std_names = []\n",
    "    start = [0]\n",
    "    end = []\n",
    "    for idx in range(len(worksheets)):\n",
    "        if group == None:\n",
    "            group = worksheets[idx].split('_')[0]\n",
    "            std_names.append(group)\n",
    "        #print(samples[idx])\n",
    "        if worksheets[idx].split('_')[0] in group:\n",
    "            pass\n",
    "        else:\n",
    "            end.append(idx)\n",
    "            start.append(idx) \n",
    "            name = worksheets[idx].split('_')[0]\n",
    "            group = name\n",
    "            std_names.append(name)\n",
    "    end.append(len(worksheets))\n",
    "\n",
    "    #print('start:', start)\n",
    "    #print('end:', end)\n",
    "    #print('std names:', std_names)\n",
    "\n",
    "    group_list = None\n",
    "\n",
    "    for key in plot_dict:\n",
    "\n",
    "        if 'full' in key:\n",
    "\n",
    "        #Create groups for plotting\n",
    "\n",
    "            samples = plot_dict[key].index.values.tolist()\n",
    "            group = None\n",
    "            group_names = []\n",
    "            start = [0]\n",
    "            end = []\n",
    "            for idx in range(len(samples)):\n",
    "                if group == None:\n",
    "                    group = samples[idx].split(' 1')[0]\n",
    "                    group_names.append(group)\n",
    "                #print(samples[idx])\n",
    "                if group in samples[idx]:\n",
    "                    pass\n",
    "                else:\n",
    "                    end.append(idx)\n",
    "                    start.append(idx) # + 1 was original\n",
    "                    name = samples[idx].split(' 1')[0]\n",
    "                    group = name\n",
    "                    group_names.append(name)\n",
    "            end.append(len(samples))\n",
    "\n",
    "            #print('start:', start)\n",
    "            #print('end:', end)\n",
    "            #print('group names:', group_names)\n",
    "            group_list = group_names\n",
    "\n",
    "    #print('group names:', group_list)\n",
    "\n",
    "    primary_std_name = {\n",
    "        'glass': \"SRM NIST 610\",\n",
    "        'glass612': \"SRM NIST 612\",\n",
    "        'glassBHVO': \"BHVO-2G\",\n",
    "        'ttn': \"MKED-1\",\n",
    "    }\n",
    "    \n",
    "    \n",
    "    for std in std_names:\n",
    "        #print(std)\n",
    "        for group in group_list:\n",
    "            #print(group)\n",
    "            ratio_plot(group, std, False)\n",
    "            new_string = group + '_PrimaryStd_' + primary_std_name[std]\n",
    "    \n",
    "            filename = os.path.join(MYDIR, new_string + '.pdf')\n",
    "            mergedObject.append(PdfFileReader(filename, 'rb'))\n",
    "    \n",
    "    if '.pdf' in output_name:\n",
    "        pass\n",
    "    else:\n",
    "        output_name = output_name + '.pdf'\n",
    "    \n",
    "     \n",
    "    mergedObject.write(output_name)\n",
    "\n",
    "    print(f'PDF file named: {output_name} is complete.')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "ratio_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# excel_name = '06May_ttnSS2_NP2_processed.xlsx'\n",
    "# files_ranked_toEXCEL(tester, excel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '0416_glass_SS_NPII_baseline.xlsx'\n",
    "#calc_dict = calc_CPS(read_np2_timeseries(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '06May_ttnSS2_NP2_baseline_corrected.xlsx'\n",
    "# SS_dict = calc_CPS(read_np2_timeseries(filename))\n",
    "# excel_name = str(filename.split('.')[0]) + '_processed.xlsx'\n",
    "\n",
    "# files_process_toEXCEL(SS_dict, excel_name)\n",
    "\n",
    "# U_Pb_report(SS_dict, 'SS2_6May.pdf', True, 'Splitstream_06May2021_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '0416_ttn_SS_NP2_data1.xlsx'\n",
    "# ttn_dict = calc_CPS(read_np2_timeseries(filename))\n",
    "\n",
    "# U_Pb_report(ttn_dict, 'titaniteTE.pdf',True, 'Titanite_splitstream_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U_Pb_report(calc_dict, 'glassTE.pdf',True, 'Glass_splitstream_results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
