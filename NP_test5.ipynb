{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###Made by Khalil Droubi\n",
    "###To process Iolite baseline-subtracted NP-II files for BB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To Do:\n",
    "\n",
    "-Test out Error minimization\n",
    "\n",
    "-Determine if filtering is the correct way to remove negative measurements from dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import re\n",
    "import copy\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "from scipy.stats import linregress\n",
    "\n",
    "#Graphing stuff\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "# %pip install seaborn\n",
    "# import seaborn as sns\n",
    "\n",
    "#%pip install PyPDF2\n",
    "from PyPDF2 import PdfFileMerger, PdfFileReader\n",
    "\n",
    "#%pip install pdfkit\n",
    "import pdfkit\n",
    "\n",
    "#pd.set_option(\"display.precision\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for calculation and EXCEL export\n",
    "def read_np2_timeseries(excel_file):\n",
    "    ''' Excel input file is your baseline corrected time series export from Iolite for the NP-II.'''\n",
    "    df = pd.read_excel(excel_file, sheet_name = None)\n",
    "    keys = df.keys()\n",
    "    header_row = 0\n",
    "    new_dict = {}\n",
    "    for key in keys:\n",
    "        if '.' in key: #Kind of hard-coded right now, so if names get weird may need to change\n",
    "            \n",
    "            df_test = df[key]\n",
    "\n",
    "            df_test.columns = df_test.iloc[header_row]\n",
    "            df_test = df_test.drop(header_row)\n",
    "            df_test = df_test.reset_index(drop=True)\n",
    "            \n",
    "#             test1_new = df_test[['Absolute Time',\n",
    "#              'Elapsed Time',\n",
    "#                  'm238_CPS',\n",
    "#                  'm232_CPS',\n",
    "#                  'm208_CPS',\n",
    "#                  'm207_CPS',\n",
    "#                  'm206_CPS',\n",
    "#                  'm204_CPS',\n",
    "#                  'm202_CPS',]]\n",
    "            \n",
    "            new_string = key.split('time')[0].rstrip()\n",
    "            new_dict[new_string] = df_test #test1_new\n",
    "    return new_dict\n",
    "\n",
    "def calc_CPS(np2_dict):\n",
    "    columns = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     'm238_CPS',\n",
    "     'm232_CPS',\n",
    "     'm208_CPS',\n",
    "     'm207_CPS',\n",
    "     'm206_CPS',\n",
    "     'm204_CPS',\n",
    "     'm202_CPS']\n",
    "\n",
    "    new_col = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     '238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "\n",
    "    cut_col = ['238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "\n",
    "    calc_dict = {}\n",
    "    for key in np2_dict:\n",
    "        #print(key)\n",
    "        test_df1 = np2_dict[key]\n",
    "\n",
    "        for col in columns:\n",
    "                test_df2 = test_df1.apply(lambda x: x * 62500000 if 'CPS' in x.name else x)\n",
    "                test_df2 = test_df2[['Absolute Time',\n",
    "             'Elapsed Time',\n",
    "                 'm238_CPS',\n",
    "                 'm232_CPS',\n",
    "                 'm208_CPS',\n",
    "                 'm207_CPS',\n",
    "                 'm206_CPS',\n",
    "                 'm204_CPS',\n",
    "                 'm202_CPS',]]\n",
    "        test_df2.columns = new_col\n",
    "        test_df2 = test_df2[cut_col]\n",
    "        result = pd.concat([test_df1, test_df2], axis=1)\n",
    "        \n",
    "         #Calculating OPZ\n",
    "        result['OPZ_238'] = result.apply(lambda x: x['m238'] - x['m238_CPS'], axis=1)\n",
    "        result['OPZ_232'] = result.apply(lambda x: x['m232'] - x['m232_CPS'], axis=1)\n",
    "        result['OPZ_208'] = result.apply(lambda x: x['m208'] - x['m208_CPS'], axis=1)\n",
    "        result['OPZ_207'] = result.apply(lambda x: x['m207'] - x['m207_CPS'], axis=1)\n",
    "        result['OPZ_206'] = result.apply(lambda x: x['m206'] - x['m206_CPS'], axis=1)\n",
    "        result['OPZ_204'] = result.apply(lambda x: x['m204'] - x['m204_CPS'], axis=1)\n",
    "        result['OPZ_202'] = result.apply(lambda x: x['m202'] - x['m202_CPS'], axis=1)\n",
    "        \n",
    "        #Calculating Ratios\n",
    "        result['206/238'] = result.apply(lambda x: x['206_CPS']/x['238_CPS'], axis=1)\n",
    "        result['208/232'] = result.apply(lambda x: x['208_CPS']/x['232_CPS'], axis=1)\n",
    "        result['207/206'] = result.apply(lambda x: x['207_CPS']/x['206_CPS'], axis=1)\n",
    "        result['208/206'] = result.apply(lambda x: x['208_CPS']/x['206_CPS'], axis=1)\n",
    "        result['206/204'] = result.apply(lambda x: x['206_CPS']/x['204_CPS'], axis=1)\n",
    "        result['208/204'] = result.apply(lambda x: x['208_CPS']/x['204_CPS'], axis=1)\n",
    "        result['207/204'] = result.apply(lambda x: x['207_CPS']/x['204_CPS'], axis=1)\n",
    "        \n",
    "        calc_dict[key] = result\n",
    "    \n",
    "    return calc_dict\n",
    "\n",
    "def ranked_minimization(sheet, ratio, reject_percentage = 20):\n",
    "\n",
    "    mytest = tester[sheet].copy(deep=True)\n",
    "\n",
    "    df_mean_before = mytest[ratio].mean()\n",
    "    df_1std_before = mytest[ratio].std()\n",
    "    df_count_before = mytest[ratio].count()\n",
    "    df_2se_perc_before = (2 * mytest[ratio].sem()) / df_mean_before * 100\n",
    "\n",
    "    dif_mean = ratio + '_dif_from_mean'\n",
    "    dif_1SD = ratio + '_dif_from_1SD'\n",
    "    mytest[dif_mean] = mytest.apply(lambda x: abs(x[ratio] - df_mean_before), axis=1)\n",
    "    mytest[dif_1SD] = mytest.apply(lambda x: x[dif_mean] - df_1std_before, axis=1)\n",
    "\n",
    "\n",
    "    mytest2 = mytest.sort_values(by = dif_1SD, ascending = False)\n",
    "    #mytest2.head()\n",
    "\n",
    "    ratios_to_reject = int(mytest[ratio].count() * reject_percentage / 100)\n",
    "    #print(ratios_to_reject)\n",
    "\n",
    "    after_rejection = mytest2[ratios_to_reject:]\n",
    "\n",
    "    df_mean_after = after_rejection[ratio].mean()\n",
    "    df_1std_after = after_rejection[ratio].std()\n",
    "    df_count_after = after_rejection[ratio].count()\n",
    "    df_2se_perc_after = (2 * after_rejection[ratio].sem()) / df_mean_after * 100\n",
    "\n",
    "    # print(df_mean_after)\n",
    "    # print(df_1std_after)\n",
    "    # print(df_2se_perc_after)\n",
    "\n",
    "    results_dict = {}\n",
    "    \n",
    "    results_dict['avg_before'] = df_mean_before\n",
    "    results_dict['1sd_before'] = df_1std_before\n",
    "    results_dict['2se%_before'] = df_2se_perc_before\n",
    "    results_dict['avg_after'] = df_mean_after\n",
    "    results_dict['1sd_after'] = df_1std_after\n",
    "    results_dict['2se%_after'] = df_2se_perc_after\n",
    "    \n",
    "    return results_dict\n",
    "\n",
    "def statistics_NP2(calc_dict):\n",
    "    calc_list = ['238_CPS', '232_CPS',\n",
    "           '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "           '208/232', '207/206', '208/206', '206/204','208/204','207/204'  ]\n",
    "    mega_dict = {}\n",
    "\n",
    "    for sheet in calc_dict:\n",
    "        tester = calc_dict[sheet]\n",
    "        stats_dict = {}\n",
    "        for col in tester:\n",
    "\n",
    "            if col in calc_list:\n",
    "                #print(col)\n",
    "                if '/' in col:\n",
    "                    key = col + '_before rejection'\n",
    "                else:\n",
    "                    key = col + '_mean'\n",
    "                df_mean = tester[col].mean()\n",
    "                stats_dict[key] = df_mean\n",
    "                df_precision = (2 * tester[col].sem()) / df_mean * 100\n",
    "                stats_dict[col + '_se%'] = df_precision\n",
    "            if 'OPZ' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean()\n",
    "                \n",
    "        stats_dict['Time (s)'] = tester['Elapsed Time'].max()\n",
    "        \n",
    "        #new_string = sheet.replace('time series data', '')\n",
    "        new_string = sheet.split('time')[0].rstrip()\n",
    "        mega_dict[new_string] = stats_dict\n",
    "\n",
    "    df_1 = pd.DataFrame(mega_dict)\n",
    "    df_flip = pd.DataFrame.transpose(df_1)\n",
    "    return df_flip\n",
    "\n",
    "def statistics_ranktest(calc_dict):\n",
    "    calc_list = ['238_CPS', '232_CPS',\n",
    "           '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "           '208/232', '207/206', '208/206', '206/204','208/204','207/204'  ]\n",
    "    mega_dict = {}\n",
    "\n",
    "    for sheet in calc_dict:\n",
    "        tester = calc_dict[sheet]\n",
    "        stats_dict = {}\n",
    "        for col in tester:\n",
    "\n",
    "            if col in calc_list:\n",
    "                #print(col)\n",
    "                if '/' in col:\n",
    "                    key_bf = col + '_before rejection'\n",
    "                    key_af = col + '_after rejection'\n",
    "                    key_bf_se = col + '_before rejection 2se%'\n",
    "                    key_af_se = col + '_after rejection 2se%'\n",
    "                    \n",
    "                    ranked_dict = ranked_minimization(sheet, col)\n",
    "                    stats_dict[key_bf] = ranked_dict['avg_before']\n",
    "                    stats_dict[key_bf_se] = ranked_dict['2se%_before']\n",
    "                    stats_dict[key_af] = ranked_dict['avg_after']\n",
    "                    stats_dict[key_af_se] = ranked_dict['2se%_after']\n",
    "                else:\n",
    "                    key = col + '_mean'\n",
    "                    df_mean = tester[col].mean()\n",
    "                    stats_dict[key] = df_mean\n",
    "                    df_precision = (2 * tester[col].sem()) / df_mean * 100\n",
    "                    stats_dict[col + '_se%'] = df_precision\n",
    "            if 'OPZ' in col:\n",
    "                 stats_dict[col + '_mean'] = tester[col].mean()\n",
    "                \n",
    "        stats_dict['Time (s)'] = tester['Elapsed Time'].max()\n",
    "        \n",
    "        #new_string = sheet.replace('time series data', '')\n",
    "        new_string = sheet.split('time')[0].rstrip()\n",
    "        mega_dict[new_string] = stats_dict\n",
    "\n",
    "    df_1 = pd.DataFrame(mega_dict)\n",
    "    df_flip = pd.DataFrame.transpose(df_1)\n",
    "    return df_flip\n",
    "\n",
    "def files_ranked_toEXCEL(calc_dict, excel_name):\n",
    "    stats = statistics_ranktest(calc_dict)\n",
    "    with pd.ExcelWriter(excel_name) as writer:\n",
    "        for sheet in calc_dict:\n",
    "            calc_dict[sheet].to_excel(writer, sheet_name = sheet, index = False)\n",
    "        \n",
    "        stats.to_excel(writer, sheet_name = 'Statistics', index = True)\n",
    "    new_filename = str(excel_name.split('.')[0]) + '_statistics.xlsx'\n",
    "    with pd.ExcelWriter(new_filename) as writer:\n",
    "        stats.to_excel(writer, sheet_name = 'Statistics', index = True)\n",
    "\n",
    "def files_process_toEXCEL(calc_dict, excel_name):\n",
    "    with pd.ExcelWriter(excel_name) as writer:\n",
    "        for sheet in calc_dict:\n",
    "            calc_dict[sheet].to_excel(writer, sheet_name = sheet, index = False)\n",
    "        \n",
    "        statistics_NP2(calc_dict).to_excel(writer, sheet_name = 'Statistics', index = True)\n",
    "\n",
    "def file_process_combine(filename):\n",
    "    calc_dict = calc_CPS(read_np2_timeseries(filename))\n",
    "    new_filename = str(filename.split('.')[0]) + '_processed.xlsx'\n",
    "    files_process_toEXCEL(calc_dict, new_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functons for graphing and report generation\n",
    "def U_Pb_plots(calc_dict, sample, choice = True):\n",
    "    key_list = ['238_CPS', '232_CPS',\n",
    "       '208_CPS', '207_CPS', '206_CPS', '204_CPS', '202_CPS', '206/238',\n",
    "       '208/232', '207/206', '208/206', '206/204']\n",
    "    \n",
    "    zet = calc_dict[sample]\n",
    "    new_string = sample.split('time')[0].rstrip()\n",
    "    y_list = []\n",
    "    for key in key_list:\n",
    "        y_list.append(zet[key])\n",
    "    \n",
    "    x = zet['Elapsed Time']\n",
    "    \n",
    "    fig, axs = plt.subplots(4, 3, sharex = True, figsize = (12, 12))\n",
    "    fig.suptitle(new_string, fontsize=24)\n",
    "    \n",
    "    ax_list = [\n",
    "        axs[0, 0], \n",
    "        axs[0, 1],   \n",
    "        axs[0, 2], \n",
    "        axs[1, 0], \n",
    "        axs[1, 1],\n",
    "        axs[1, 2],\n",
    "        axs[2, 0], \n",
    "        axs[2, 1], \n",
    "        axs[2, 2],\n",
    "        axs[3, 0], \n",
    "        axs[3, 1], \n",
    "        axs[3, 2]   \n",
    "        ]\n",
    "\n",
    "    axs[0, 0].plot(x, y_list[0])\n",
    "    axs[0, 1].plot(x, y_list[1])\n",
    "    axs[0, 2].plot(x, y_list[2])\n",
    "    axs[1, 0].plot(x, y_list[3])\n",
    "    axs[1, 1].plot(x, y_list[4])\n",
    "    axs[1, 2].plot(x, y_list[5])\n",
    "    axs[2, 0].plot(x, y_list[6])\n",
    "    axs[2, 1].plot(x, y_list[7])\n",
    "    axs[2, 2].plot(x, y_list[8])\n",
    "    axs[3, 0].plot(x, y_list[9])\n",
    "    axs[3, 0].set(xlabel = 'Time (s)')\n",
    "    axs[3, 1].plot(x, y_list[10])\n",
    "    axs[3, 1].set(xlabel = 'Time (s)')\n",
    "    axs[3, 2].plot(x, y_list[11])\n",
    "    axs[3, 2].set(xlabel = 'Time (s)')\n",
    "    for idx in range(len(ax_list)):\n",
    "        ax_list[idx].ticklabel_format(axis='y', style='sci', scilimits=(0,0))\n",
    "        ax_list[idx].set_title(key_list[idx])\n",
    "        y_mean = [np.mean(y_list[idx])]*len(x)\n",
    "        # Plot the average line\n",
    "        mean_line = ax_list[idx].plot(x,y_mean, label='Mean', linestyle='--', color = \"black\")\n",
    "        # Make a legend\n",
    "        legend = ax_list[idx].legend(loc='upper right')\n",
    "    \n",
    "    MYDIR = (\"Figures\")\n",
    "    CHECK_FOLDER = os.path.isdir(MYDIR)\n",
    "\n",
    "    # If folder doesn't exist, then create it.\n",
    "    if not CHECK_FOLDER:\n",
    "        os.makedirs(MYDIR)\n",
    "        #print(\"created folder : \", MYDIR)\n",
    "    \n",
    "    #new_string = sample.replace('time series data', '').rstrip()\n",
    "    \n",
    "    filename = os.path.join(MYDIR, new_string + '.pdf')\n",
    "    plt.savefig(filename)\n",
    "    print('Plot for ', new_string, \" is complete.\")\n",
    "    \n",
    "    if choice == False:\n",
    "        plt.close()\n",
    "    #else:\n",
    "        #plt.close()\n",
    "        \n",
    "\n",
    "def U_Pb_report(calc_dict, intro_filename, intro = False, output_name = 'U-Pb_output.pdf'):\n",
    "    MYDIR = (\"Figures\")\n",
    "    mergedObject = PdfFileMerger()\n",
    "    \n",
    "    if intro:\n",
    "        mergedObject.append(PdfFileReader(intro_filename, 'rb'))\n",
    "        print(f'Succesfully incorporated {intro_filename} into PDF.')\n",
    "    pd.set_option('precision', 2)\n",
    "    stats = statistics_NP2(calc_dict)\n",
    "    stat_dict = {}\n",
    "    stat_dict['stat1'] = stats.iloc[:, 14:]\n",
    "    stat_dict['stat2'] = stats.iloc[:, :8]\n",
    "    stat_dict['stat3'] = stats.iloc[:, 8:14]\n",
    "    html_list = []\n",
    "\n",
    "    for key in stat_dict:\n",
    "        name = key + \".pdf\"\n",
    "        stats_html = stat_dict[key].to_html()\n",
    "        pdfkit.from_string(stats_html, name)\n",
    "        mergedObject.append(PdfFileReader(name, 'rb'))\n",
    "\n",
    "    file_list = []\n",
    "    keys = calc_dict.keys()\n",
    "\n",
    "    for key in keys:\n",
    "        #print(key)\n",
    "        U_Pb_plots(calc_dict, key, False)\n",
    "        new_string = key.split('time')[0].rstrip()\n",
    "        filename = os.path.join(MYDIR, new_string + '.pdf')\n",
    "\n",
    "        mergedObject.append(PdfFileReader(filename, 'rb'))\n",
    "\n",
    "    if '.pdf' in output_name:\n",
    "        pass\n",
    "    else:\n",
    "        output_name = output_name + '.pdf'\n",
    "    \n",
    "    #output_name = \"U-Pb_output.pdf\"  \n",
    "    mergedObject.write(output_name)\n",
    "\n",
    "    print(f'PDF file named: {output_name} is complete.')        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Currently deprecated. Need to update to reflect calc_CPS()\n",
    "\n",
    "def calc_CPS2(np2_dict):\n",
    "    ''' Eliminates negative values in 238, 232, 208, 207, 206, and 204'''\n",
    "    columns = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     'm238_CPS',\n",
    "     'm232_CPS',\n",
    "     'm208_CPS',\n",
    "     'm207_CPS',\n",
    "     'm206_CPS',\n",
    "     'm204_CPS',\n",
    "     'm202_CPS']\n",
    "\n",
    "    new_col = ['Absolute Time',\n",
    "     'Elapsed Time',\n",
    "     '238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "\n",
    "    cut_col = ['238_CPS',\n",
    "     '232_CPS',\n",
    "     '208_CPS',\n",
    "     '207_CPS',\n",
    "     '206_CPS',\n",
    "     '204_CPS',\n",
    "     '202_CPS']\n",
    "    key_list = ['m238_CPS',\n",
    "     'm232_CPS',\n",
    "     'm208_CPS',\n",
    "     'm207_CPS',\n",
    "     'm206_CPS',\n",
    "     'm204_CPS']\n",
    "\n",
    "    calc_dict = {}\n",
    "    for key in np2_dict:\n",
    "        #print(key)\n",
    "        test_df1 = np2_dict[key]\n",
    "        \n",
    "\n",
    "        test_df_new = test_df1\n",
    "        for item in key_list:\n",
    "            filter_mass = test_df_new[item] > 0\n",
    "            test_df_new = test_df_new[filter_mass]\n",
    "            #print(test_df_new.shape)\n",
    "        test_df1 = test_df_new\n",
    "        \n",
    "        for col in columns:\n",
    "                test_df2 = test_df1.apply(lambda x: x * 62500000 if 'CPS' in x.name else x)\n",
    "        test_df2.columns = new_col\n",
    "        test_df2 = test_df2[cut_col]\n",
    "        result = pd.concat([test_df1, test_df2], axis=1)\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        #Calculating ratios\n",
    "        result['206/238'] = result.apply(lambda x: x['206_CPS']/x['238_CPS'], axis=1)\n",
    "        result['208/232'] = result.apply(lambda x: x['208_CPS']/x['232_CPS'], axis=1)\n",
    "        result['207/206'] = result.apply(lambda x: x['207_CPS']/x['206_CPS'], axis=1)\n",
    "        result['208/206'] = result.apply(lambda x: x['208_CPS']/x['206_CPS'], axis=1)\n",
    "        result['206/204'] = result.apply(lambda x: x['206_CPS']/x['204_CPS'], axis=1)\n",
    "        \n",
    "        calc_dict[key] = result\n",
    "    \n",
    "    return calc_dict\n",
    "\n",
    "def file_process_combine2(filename):\n",
    "    calc_dict = calc_CPS2(read_np2_timeseries(filename))\n",
    "    new_filename = str(filename.split('.')[0]) + '_processed.xlsx'\n",
    "    files_process_toEXCEL(calc_dict, new_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = '06May_ttnSS2_NP2_baseline_corrected.xlsx'\n",
    "test_df = read_np2_timeseries(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "test_df.keys()\n",
    "test_df['SRM NIST 610 1.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tester = calc_CPS(test_df)\n",
    "tester.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# excel_name = '06May_ttnSS2_NP2_processed.xlsx'\n",
    "# files_ranked_toEXCEL(tester, excel_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tester['SRM NIST 610 1.1']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "statistics_NP2(tester).keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "statistics_ranktest(tester)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#INPUT\n",
    "reject_percentage = 20\n",
    "\n",
    "sheet = 'SRM NIST 610 1.1'\n",
    "ratio = '208/232'\n",
    "#END INPUT\n",
    "    \n",
    "\n",
    "\n",
    "ranked_minimization(sheet, ratio, reject_percentage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#filename = '0416_glass_SS_NPII_baseline.xlsx'\n",
    "#calc_dict = calc_CPS(read_np2_timeseries(filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '06May_ttnSS2_NP2_baseline_corrected.xlsx'\n",
    "# SS_dict = calc_CPS(read_np2_timeseries(filename))\n",
    "# excel_name = str(filename.split('.')[0]) + '_processed.xlsx'\n",
    "\n",
    "# files_process_toEXCEL(SS_dict, excel_name)\n",
    "\n",
    "# U_Pb_report(SS_dict, 'SS2_6May.pdf', True, 'Splitstream_06May2021_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filename = '0416_ttn_SS_NP2_data1.xlsx'\n",
    "# ttn_dict = calc_CPS(read_np2_timeseries(filename))\n",
    "\n",
    "# U_Pb_report(ttn_dict, 'titaniteTE.pdf',True, 'Titanite_splitstream_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#U_Pb_report(calc_dict, 'glassTE.pdf',True, 'Glass_splitstream_results')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
